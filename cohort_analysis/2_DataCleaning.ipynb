{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dict = {\n",
    "    ' Other': 'Unknown',\n",
    "    ' Unknown': 'Unknown',\n",
    "    ' Patient Refused': 'Unknown',\n",
    "    ' Other ~ Unknown': 'Unknown',\n",
    "\n",
    "    ' White or Caucasian': 'White',\n",
    "    ' Other ~ White or Caucasian': 'White',\n",
    "    ' Patient Refused ~ White or Caucasian': 'White',\n",
    "    ' Unknown ~ White or Caucasian': 'White',\n",
    "\n",
    "    ' Black or African American': 'Black or African American',\n",
    "    ' Black or African American ~ Other': 'Black or African American',\n",
    "    ' Black or African American ~ Unknown': 'Black or African American',\n",
    "    ' Black or African American ~ Other ~ Unknown': 'Black or African American',\n",
    "\n",
    "    ' Asian ~ Unknown': 'Asian',\n",
    "    ' Asian': 'Asian',\n",
    "    ' Asian ~ Asian Indian': 'Asian',\n",
    "    ' Asian ~ Filipino': 'Asian',\n",
    "    ' Nepalese ~ Other': 'Asian',\n",
    "    ' Pakistani': 'Asian',\n",
    "    ' Nepalese': 'Asian',\n",
    "    ' Asian Indian ~ Unknown': 'Asian',\n",
    "    ' Bhutanese ~ Other': 'Asian',\n",
    "    ' Asian ~ Chinese': 'Asian',\n",
    "    ' Asian ~ Other': 'Asian',\n",
    "    ' Indonesian': 'Asian',\n",
    "    ' Asian Indian': 'Asian',\n",
    "    ' Laotian ~ Other': 'Asian',\n",
    "    ' Asian ~ Vietnamese': 'Asian',\n",
    "\n",
    "    ' Other Pacific Islander': 'Native Hawaiian or Other Pacific Islander',\n",
    "    ' Guamanian': 'Native Hawaiian or Other Pacific Islander',\n",
    "\n",
    "    ' American Indian or Alaskan Native': 'American Indian or Alaska Native',   \n",
    "    ' American Indian or Alaskan Native ~ Other': 'American Indian or Alaska Native',\n",
    "\n",
    "#\"More than One Race\" See the highest % race assignment for Table 4 in https://wonder.cdc.gov/wonder/help/populations/bridged-race/PublicHealthReports119-2-p192.pdf\n",
    "# see also https://doh.wa.gov/sites/default/files/legacy/Documents/1500/RaceEthnGuidelines.pdf\n",
    "# see also https://www.cdc.gov/nchs/data/dvs/Multiple_race_documentation_5-10-04.pdf\n",
    "\n",
    "    ' Palauan ~ White or Caucasian': 'More than one race',\n",
    "    ' Bangladeshi ~ White or Caucasian': 'More than one race',\n",
    "    ' American Indian or Alaskan Native ~ White or Caucasian': 'More than one race',\n",
    "    ' Asian Indian ~ White or Caucasian': 'More than one race',\n",
    "    ' White or Caucasian ~ Yapese': 'More than one race',\n",
    "    ' Asian ~ White or Caucasian': 'More than one race',\n",
    "    ' Black or African American ~ White or Caucasian': 'More than one race',\n",
    "    ' American Indian or Alaskan Native ~ Black or African American': 'More than one race',\n",
    "    ' Black or African American ~ Native Hawaiian': 'More than one race',\n",
    "    ' Black or African American ~ Indonesian ~ Other': 'More than one race',\n",
    "    ' Black or African American ~ Other ~ White or Caucasian': 'More than one race',\n",
    "}\n",
    "\n",
    "race_dict_lkp = {\n",
    "    'Unknown': 0,\n",
    "    'American Indian or Alaska Native': 1,\n",
    "    'Asian': 2,\n",
    "    'Black or African American': 3,\n",
    "    'Native Hawaiian or Other Pacific Islander': 4,\n",
    "    'White': 5,\n",
    "    'More than one race': 6,\n",
    "}\n",
    "\n",
    "\n",
    "ethnicity_dict = {\n",
    "    ' Unknown': 'Unknown',\n",
    "    ' Patient Refused': 'Unknown',\n",
    "    ' Patient Refused ~ Unknown': 'Unknown',\n",
    "    ' Hispanic or Latino ~ Not Hispanic or Latino': 'Unknown',\n",
    "\n",
    "    ' Not Hispanic or Latino': 'Not Hispanic',\n",
    "    ' Not Hispanic or Latino ~ Unknown': 'Not Hispanic',\n",
    "    ' Not Hispanic or Latino ~ Patient Refused': 'Not Hispanic',\n",
    "    ' Not Hispanic or Latino ~ Uruguayan': 'Not Hispanic',\n",
    "\n",
    "    ' Hispanic or Latino': 'Hispanic',\n",
    "    ' Puerto Rican': 'Hispanic',\n",
    "    ' Mexican American Indian': 'Hispanic',\n",
    "    ' Hispanic or Latino ~ Unknown': 'Hispanic',\n",
    "    ' Spaniard ~ Unknown': 'Hispanic',\n",
    "    ' Hispanic or Latino ~ Puerto Rican': 'Hispanic',\n",
    "    ' Peruvian': 'Hispanic',\n",
    "    ' Guatemalan ~ Honduran ~ Puerto Rican ~ Spaniard': 'Hispanic',\n",
    "    ' Central American': 'Hispanic',\n",
    "    ' Spaniard': 'Hispanic',\n",
    "    ' Puerto Rican ~ Unknown': 'Hispanic',\n",
    "    ' Dominican ~ Puerto Rican': 'Hispanic',\n",
    "    ' Mexican American': 'Hispanic',\n",
    "    ' Guatemalan': 'Hispanic',\n",
    "    ' South American Indian': 'Hispanic',\n",
    "    ' Central American Indian': 'Hispanic'\n",
    "}\n",
    "\n",
    "ethnicity_dict_lkp = {\n",
    "    'Hispanic': 1,\n",
    "    'Not Hispanic': 2,\n",
    "}\n",
    "\n",
    "insurance_dict = {\n",
    "    'Commercial': 'Private',\n",
    "    'Out of Area BC/BS': 'Private',\n",
    "    'Government Other': 'Government',\n",
    "    'Medicare': 'Medicare',\n",
    "    'Medicaid': 'Medicaid',\n",
    "    'Medicare Advantage': 'Medicare',\n",
    "    'Medicaid Managed Care': 'Medicaid',\n",
    "    'Excellus': 'Private',\n",
    "    'MVA': 'Government',\n",
    "    'Aetna': 'Private',\n",
    "    'MVP': 'Private',\n",
    "    \"Worker's Comp\": 'Government',\n",
    "    'Institutional': 'Private',\n",
    "    'UNIVERA SENIOR CHOICE MEDICARE': 'Medicare',\n",
    "    'MEDICARE PART A AND B': 'Medicare',\n",
    "    'MVP PREMIER INDIVIDUAL': 'Private',\n",
    "    'EXCELLUS': 'Private',\n",
    "    'UNITED HEALTHCARE MEDICAID': 'Medicaid'\n",
    "}\n",
    "\n",
    "insurance_dict_lkp = {\n",
    "    'Private': 1,\n",
    "    'Medicare': 2,\n",
    "    'Medicaid': 3,\n",
    "    'Government': 4\n",
    "}\n",
    "\n",
    "assessment_color_dict = {\n",
    "    'RED': 'Red',\n",
    "    'YELLOW': 'Yellow',\n",
    "    'BLUE': 'Blue'\n",
    "}\n",
    "\n",
    "assessment_color_dict_lkp = {\n",
    "    'Red': 1,\n",
    "    'Yellow': 2,\n",
    "    'Blue': 3\n",
    "}\n",
    "\n",
    "discharge_status_dict_lkp = {\n",
    "    'Home or Self Care': 1,\n",
    "    'Patient Expired': 2,\n",
    "    'To Home Health Org Care': 3,\n",
    "    'To Jail / Law Enforcement Facility': 4,\n",
    "    'To SNF (Skilled Nursing)': 5,\n",
    "    'To Inpatient Rehab Facility or Unit': 6,\n",
    "    'Left against medical advice': 7,\n",
    "    'To Hospice/Home Care': 8,\n",
    "    'To Psychiatric Hospital or Unit': 9,\n",
    "    'To Short Term Acute Care Hosp': 10,\n",
    "    'To Hospice/Medical Facility': 11,\n",
    "    'To LTC Facility (Long Term Care)': 12,\n",
    "    'Sent to SMH': 13,\n",
    "    'Sent to HH': 14,\n",
    "    'To Short Term General Hospital for Inpatient Care with Planned Hospital Readmission': 15,\n",
    "    'To Inpatient Rehab Facility or Unit with Planned Hospital Readmission': 16,\n",
    "    'To Other Facility not otherwise defined': 17,\n",
    "    'To ICF (Intermediate Care)': 18,\n",
    "    'To Federal Hospital': 19,\n",
    "    \"To Designated Cancer Ctr or Children's Hospital with Planned Hospital Readmission\": 20,\n",
    "    'Still Inpatient': 21,\n",
    "    'To Psychiatric Hospital or Unit with Planned Hospital Readmission': 22\n",
    "}\n",
    "\n",
    "covid_dict = {\n",
    "    'Yes': 1,\n",
    "    'No': 0\n",
    "}\n",
    "\n",
    "covid_dict_lkp = {\n",
    "    'Positive': 1,\n",
    "    'Negative': 0\n",
    "}\n",
    "\n",
    "sex_dict = {\n",
    "    'M': 'Male',\n",
    "    'F': 'Female'\n",
    "}\n",
    "\n",
    "\n",
    "sex_dict_lkp = {\n",
    "    'Male': 1,\n",
    "    'Female': 2\n",
    "}\n",
    "\n",
    "#Reduced Race Dictionary\n",
    "def race_ethnicity_dict (row):\n",
    "    if row['Ethnicity'] == 'Hispanic' :\n",
    "        return 'Hispanic'\n",
    "    return row['Race']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract and re-format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_num                    int64\n",
      "SubjectID                 object\n",
      "intubation_number          int64\n",
      "assessment_timepoint       int64\n",
      "vent_duration (hours)    float64\n",
      "sofa_score                 int64\n",
      "assessment_color           int64\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4605 entries, 0 to 4604\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   seq                    4605 non-null   int64  \n",
      " 1   Encounter_Number       4605 non-null   object \n",
      " 2   SubjectID              4605 non-null   object \n",
      " 3   Race                   4605 non-null   int64  \n",
      " 4   Ethnicity              4319 non-null   float64\n",
      " 5   Sex                    4605 non-null   int64  \n",
      " 6   Discharge_Status       4594 non-null   float64\n",
      " 7   Length_of_Stay (days)  4593 non-null   float64\n",
      " 8   Age_at_Admission       4601 non-null   object \n",
      " 9   Reduced_Race           4605 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(3)\n",
      "memory usage: 359.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Extract data from csv, package in df's*, and convert encounter numbers to \n",
    "study_cohort_df = pd.read_excel('VAP_DeID_2022-01-12.xlsx', sheet_name='Study_Cohort_DeID', converters={'Encounter_Number': '{:0>4}'.format, 'SubjectID':str})\n",
    "insurance_xl_df = pd.read_excel('VAP_DeID_2022-01-12.xlsx', sheet_name='Insurance_DeID', converters={'Encounter_Number': '{:0>4}'.format, 'SubjectID':str})\n",
    "covid_df = pd.read_excel('VAP_DeID_2022-01-12.xlsx', sheet_name='COVID_Status_DeID', converters={'SubjectID':str})\n",
    "blis_df = pd.read_excel('VAP_DeID_2022-01-12.xlsx', sheet_name='BLIS_ASSESSMENT_DeID', converters={'Encounter_Number': '{:0>4}'.format, 'SubjectID':str})\n",
    "admission_df = pd.read_excel('VAP_DeID_2022-01-12.xlsx', sheet_name='Admission_dXs_DeID', converters={'Encounter_Number': '{:0>4}'.format, 'SubjectID':str})\n",
    "\n",
    "#Create lookup dataframes#\n",
    "sex_lkp_df = pd.DataFrame(sex_dict_lkp.items(), columns=['Description', 'ID'])\n",
    "race_lkp_df = pd.DataFrame(race_dict_lkp.items(), columns=['Description', 'ID'])\n",
    "insurance_lkp_df = pd.DataFrame(insurance_dict_lkp.items(), columns=['Description', 'ID'])\n",
    "ethnicity_lkp_df = pd.DataFrame(ethnicity_dict_lkp.items(), columns=['Description', 'ID'])\n",
    "covid_lkp_df = pd.DataFrame(covid_dict_lkp.items(), columns=['Description', 'ID'])\n",
    "assessment_color_lkp_df = pd.DataFrame(assessment_color_dict_lkp.items(), columns=['Description', 'ID'])\n",
    "discharge_status_lkp_df = pd.DataFrame(discharge_status_dict_lkp.items(), columns=['Description', 'ID'])\n",
    "\n",
    "#Create ICD_10 lookup\n",
    "#Create ICD_10 lookup\n",
    "icd10_lkp_df = (\n",
    "    admission_df[['ICD10_dX(s)', 'dX_Name']]\n",
    "    .copy()\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    "    .dropna(subset = {'ICD10_dX(s)'})\n",
    ")\n",
    "icd10_lkp_df['ID'] = icd10_lkp_df.index\n",
    "icd10_lkp_df = icd10_lkp_df[['ID', 'ICD10_dX(s)', 'dX_Name']]\n",
    "icd10_lkp_df.columns = ['ID', 'Code', 'Description']\n",
    "\n",
    "#swap columns in LkP dataframes#\n",
    "sex_lkp_df = sex_lkp_df[['ID', 'Description']]\n",
    "race_lkp_df = race_lkp_df[['ID', 'Description']]\n",
    "insurance_lkp_df = insurance_lkp_df[['ID', 'Description']]\n",
    "ethnicity_lkp_df = ethnicity_lkp_df[['ID', 'Description']]\n",
    "covid_lkp_df = covid_lkp_df[['ID', 'Description']]\n",
    "assessment_color_lkp_df = assessment_color_lkp_df[['ID', 'Description']]\n",
    "discharge_status_lkp_df = discharge_status_lkp_df[['ID', 'Description']]\n",
    "\n",
    "#apply dictionaries\n",
    "study_cohort_df['Race'] = study_cohort_df['Race'].map(race_dict).map(race_dict_lkp)\n",
    "study_cohort_df['Ethnicity'] = study_cohort_df['Ethnicity'].map(ethnicity_dict).map(ethnicity_dict_lkp)#.astype(CategoricalDtype(categories={1:'Hispanic', 2:'Not Hispanic'})).cat.codes\n",
    "study_cohort_df['Sex'] = study_cohort_df['Sex'].map(sex_dict).map(sex_dict_lkp)#.astype(CategoricalDtype(categories={1:'Male', 2:'Female'})).cat.codes\n",
    "study_cohort_df['Discharge_Status'] = study_cohort_df['Discharge_Status'].map(discharge_status_dict_lkp)\n",
    "study_cohort_df['Reduced_Race'] = study_cohort_df.apply(race_ethnicity_dict, axis=1)\n",
    "insurance_xl_df['Insurance'] = insurance_xl_df['Insurance'].map(insurance_dict).map(insurance_dict_lkp)\n",
    "covid_df['COVID_POSITIVE_N3C_Phenotype'] = covid_df['COVID_POSITIVE_N3C_Phenotype'].map(covid_dict)\n",
    "blis_df['assessment_color'] = blis_df['assessment_color'].map(assessment_color_dict).map(assessment_color_dict_lkp)\n",
    "\n",
    "print(blis_df.dtypes)\n",
    "print(study_cohort_df.info())\n",
    "\n",
    "study_cohort_df.to_pickle(\"cohort_raw.pkl\")\n",
    "admission_df.to_pickle(\"diagnoses_raw.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#included #1: Create list of SubjectIDs that have rows and relevant info in ALL of subjects_df, covid_df, insurance_xl_df, blis_df and admission_df\n",
    "included_1 = (study_cohort_df\n",
    "    .merge(covid_df[[\"SubjectID\", \"COVID_POSITIVE_N3C_Phenotype\"]], on=\"SubjectID\") #identify all subjects w/ COVID records\n",
    "    .merge(insurance_xl_df[[\"SubjectID\", \"Insurance\"]], on=\"SubjectID\")\n",
    "    .merge(blis_df[[\"SubjectID\", \"intubation_number\"]], on=\"SubjectID\")\n",
    "    .merge(admission_df[[\"SubjectID\", \"Encounter_Number\", \"ICD10_dX(s)\"]], on=[\"SubjectID\",\"Encounter_Number\"])\n",
    "    .dropna(subset=['Discharge_Status', \"ICD10_dX(s)\", \"Age_at_Admission\"]) #drop records that do not have discharge, comorbidity, or age at admission data.\n",
    "    .drop_duplicates(subset=['SubjectID', 'Encounter_Number'])\n",
    "    .reindex(columns=['SubjectID'])\n",
    ")\n",
    "\n",
    "#included #2: Identify SubjectIDs that have a 0 assessment timepoint for intubation #1\n",
    "included_2 = (blis_df\n",
    "    .where(blis_df[\"intubation_number\"]==1)\n",
    "    .where(blis_df[\"assessment_timepoint\"]==0)\n",
    "    .dropna()\n",
    "    .drop_duplicates('SubjectID')\n",
    "    .reindex(columns=['SubjectID'])\n",
    ")\n",
    "\n",
    "#Error #3: Identify SubjectIDs where: \n",
    "#(1) There is a BLIS record AND \n",
    "#(2a) # of Encounters = 1 OR (2b) # of Encounters = # of Intubations \n",
    "\n",
    "encounter_counts= (study_cohort_df\n",
    "    .merge(study_cohort_df['SubjectID']\n",
    "            .value_counts()\n",
    "            .rename_axis('SubjectID')\n",
    "            .reset_index(name='Encounter_Count')\n",
    "    )\n",
    "    .reindex(columns=[\n",
    "        'SubjectID',\n",
    "        'Encounter_Count']\n",
    "        )\n",
    ")\n",
    "\n",
    "intubation_counts= (blis_df\n",
    "    .groupby('SubjectID')\n",
    "    .max()\n",
    "    .rename(columns = {'intubation_number': 'Intubation_Count'})\n",
    "    .reset_index('SubjectID')\n",
    "    .reindex(columns=[\n",
    "        'SubjectID',\n",
    "        'Intubation_Count']\n",
    "        )\n",
    ")\n",
    "\n",
    "included_3_merge = (study_cohort_df\n",
    "    .merge(encounter_counts, on=\"SubjectID\")\n",
    "    .merge(intubation_counts, on=\"SubjectID\")\n",
    "    .drop_duplicates()\n",
    ")\n",
    "included_3 = (included_3_merge    \n",
    "    .where((included_3_merge['Encounter_Count']==1) | (included_3_merge['Encounter_Count'] == included_3_merge['Intubation_Count']))\n",
    "    .dropna(subset=['SubjectID'])\n",
    "    .drop_duplicates('SubjectID')\n",
    "    .reindex(columns=['SubjectID'])#, 'Encounter_Number'])\n",
    ")\n",
    "\n",
    "#Compile full list of error-free SubjectIDs\n",
    "included = (included_1\n",
    "    .merge(included_2)\n",
    "    .merge(included_3)\n",
    "    #.rename(columns={'Encounter_Number':\"EncounterID\"})\n",
    ")\n",
    "\n",
    "###CREATE Encounter-to-Intubation crosswalks ###\n",
    "#   https://stackoverflow.com/questions/37997668/pandas-number-rows-within-group-in-increasing-order\n",
    "#   https://stackoverflow.com/questions/55577385/pandas-copy-each-row-n-times-depending-on-column-value\n",
    "\n",
    "#create Encounter-to-Intubation crosswalk for all SubjectIDs with 1 Encounters\n",
    "vent_encounter_1_df = (\n",
    "    included_3_merge\n",
    "    .where(included_3_merge['Encounter_Count']==1) #select all Subject_IDs where only 1 encounter\n",
    "    .rename(columns={'Encounter_Number':'EncounterID'})\n",
    "    .assign(encounter_number = 1) #create column 'encounter_number' and assign value of 1 to all rows\n",
    "    .loc[included_3_merge.index.repeat(included_3_merge['Intubation_Count'])]     #copy each row N times, where N is value in 'Intubation_Count'\n",
    "    # method: https://stackoverflow.com/questions/55577385/pandas-copy-each-row-n-times-depending-on-column-value\n",
    ")\n",
    "vent_encounter_1_df = (\n",
    "    vent_encounter_1_df\n",
    "    .assign(intubation_number = vent_encounter_1_df.groupby(['SubjectID', 'EncounterID']).cumcount()+1) #assign ordering of intubations by 'SubjectID' and 'EncounterID'\n",
    "    # method: https://stackoverflow.com/questions/37997668/pandas-number-rows-within-group-in-increasing-order\n",
    "    .dropna(subset=['SubjectID'])\n",
    "    .drop_duplicates()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "#create Encounter-to-Intubation crosswalk for all SubjectIDs with <1 Encounters\n",
    "vent_encounter_multi_df = (\n",
    "    included_3_merge\n",
    "    .where((included_3_merge['Encounter_Count'] !=1) &\n",
    "            (included_3_merge['Encounter_Count'] == included_3_merge['Intubation_Count']))\n",
    "    .rename(columns={'Encounter_Number':'EncounterID'})\n",
    ")\n",
    "vent_encounter_multi_df = (\n",
    "    vent_encounter_multi_df\n",
    "    .assign(encounter_number = vent_encounter_multi_df.groupby(['SubjectID']).cumcount()+1)\n",
    "    .assign(intubation_number = included_3_merge.groupby(['SubjectID']).cumcount()+1) #assign ordering of intubations within subject-encounter pairs\n",
    "    .dropna(subset=['SubjectID'])\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "#Concat _1 and _multi frames to create full Encounter-to-Intubation crosswalk\n",
    "vent_encounter_df = pd.concat([vent_encounter_1_df, vent_encounter_multi_df]) #add rows from vent_encounter_multi to bottom of vent_encounter_1\n",
    "vent_encounter_df = (\n",
    "    vent_encounter_df\n",
    "    .reindex(columns = ['SubjectID', \n",
    "            'EncounterID',\n",
    "            'intubation_number',\n",
    "            'Encounter_Count',\n",
    "            'Discharge_Status',\n",
    "            ]\n",
    "        )\n",
    "    .reset_index(drop=True)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Encounters:  4220\n",
      "Number of Unique Subjects:  3967\n",
      "Number of Unique Subjects:  3512\n",
      "Number of Unique Encounters:  3740\n",
      "Number of Unique Subjects:  3512\n"
     ]
    }
   ],
   "source": [
    "print('Number of Unique Encounters: ', vent_encounter_df['EncounterID'].drop_duplicates().count())\n",
    "print('Number of Unique Subjects: ', vent_encounter_df['SubjectID'].drop_duplicates().count())\n",
    "\n",
    "#print('Number of Unique Encounters: ', included['EncounterID'].drop_duplicates().count())\n",
    "print('Number of Unique Subjects: ', included['SubjectID'].drop_duplicates().count())\n",
    "\n",
    "check_1 = (vent_encounter_df\n",
    "    .merge(included, on='SubjectID')\n",
    "    .reindex(columns=['SubjectID', 'EncounterID'])\n",
    "    .drop_duplicates()\n",
    ")\n",
    "print('Number of Unique Encounters: ', check_1['EncounterID'].drop_duplicates().count())\n",
    "print('Number of Unique Subjects: ', check_1['SubjectID'].drop_duplicates().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Life Expectancy and Comorbidity Adjusted Triage Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate:\n",
    "# (1) Life Expectancy and Comorbidity-Adjusted Life Expectancy\n",
    "# (2) Colorado Crisis Standards of Care Score\n",
    "# (3) Bhavani Multi-Principle Score\n",
    "\n",
    "%run 2a_LifeExpCalc.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create subject dataframe\n",
    "subject_df = (study_cohort_df[['SubjectID', 'Race', 'Ethnicity', 'Sex']]\n",
    "    .merge(included) #remove all error SubjectIDs\n",
    "    .drop_duplicates()\n",
    "    .sort_values(by=\"SubjectID\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "#create encounter dataframe\n",
    "encounter_df = (study_cohort_df[['SubjectID', 'Encounter_Number', 'Discharge_Status', 'Length_of_Stay (days)', 'Age_at_Admission']]\n",
    "    .merge(included) #remove all error SubjectIDs\n",
    "    .merge(covid_df[[\"SubjectID\", \"COVID_POSITIVE_N3C_Phenotype\"]], on=\"SubjectID\")\n",
    "    .merge(encounter_le[['Encounter_Number', 'Life_Exp', 'Cho_Tier', 'Cho_LE']], on = \"Encounter_Number\") \n",
    "    .drop_duplicates()\n",
    "    .rename(columns={\n",
    "        'Encounter_Number': 'EncounterID', \n",
    "        'Length_of_Stay (days)': 'Length_of_Stay_Days', \n",
    "        'COVID_POSITIVE_N3C_Phenotype': 'COVID_Status'\n",
    "        })\n",
    "    .sort_values(by=\"EncounterID\")\n",
    "    .merge(encounter_comorbid, on='EncounterID') #bring in Charlson and Elixhauser scores\n",
    "    .reindex(columns=[\n",
    "        'EncounterID',\n",
    "        'SubjectID',\n",
    "        'Discharge_Status',\n",
    "        'Length_of_Stay_Days',\n",
    "        'Age_at_Admission',\n",
    "        'COVID_Status',\n",
    "        'CCS_raw',\n",
    "        'CCS_age',\n",
    "        'CCS_Colorado',\n",
    "        'ECI_raw',\n",
    "        'Life_Exp', \n",
    "        'Cho_Tier', \n",
    "        'Cho_LE']\n",
    "        )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# create insurance dataframe\n",
    "insurance_df = (insurance_xl_df[['SubjectID', 'Encounter_Number', 'Insurance']]\n",
    "    .merge(included) #remove all error SubjectIDs\n",
    "    .drop_duplicates(subset=['SubjectID', 'Encounter_Number', 'Insurance'])\n",
    "    .rename(columns={'Encounter_Number': 'EncounterID', 'Insurance':'Insurance_CD'})\n",
    "    .sort_values(by=[\"SubjectID\", \"EncounterID\"])\n",
    "    .reindex(columns=[\n",
    "        'ID',\n",
    "        'SubjectID',\n",
    "        'EncounterID',\n",
    "        'Insurance_CD',]\n",
    "        )\n",
    "#    .set_index(['SubjectID', 'EncounterID'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "#create comorbidity dataframe\n",
    "comorbid_df = (admission_df[['SubjectID', 'Encounter_Number', 'ICD10_dX(s)', 'Reason_Visit']]\n",
    "    .merge(included, on=\"SubjectID\")\n",
    "    .drop_duplicates(subset=['SubjectID', 'Encounter_Number', 'ICD10_dX(s)'])\n",
    "    .rename(columns={'Encounter_Number': 'EncounterID', 'ICD10_dX(s)':'ICD_10'})\n",
    "    .sort_values(by=[\"SubjectID\", \"EncounterID\"])\n",
    "    .reindex(columns=[\n",
    "        'ID',\n",
    "        'SubjectID', \n",
    "        'EncounterID',\n",
    "        'ICD_10',\n",
    "        'Reason_Visit']\n",
    "        )\n",
    "#    .set_index(['SubjectID', 'EncounterID'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "#create ventilator table\n",
    "vent_df = (blis_df\n",
    "    .merge(included, on=['SubjectID']) #remove all error SubjectIDs\n",
    "    .merge(vent_encounter_df, on=['SubjectID', 'intubation_number'])  #associate Encounter #s with SubjectIDs & Intubations\n",
    "    .merge(encounter_comorbid, on='EncounterID')\n",
    "    .assign(Colorado_S = lambda df_: df_.apply(colorado_sofa_calc, axis=1))\n",
    "    .assign(seq_num = lambda vent_df_y: #create a unique ID for each row\n",
    "                vent_df_y['EncounterID'].map(str) + '-' + \n",
    "                vent_df_y['intubation_number'].map(str) + '-' + \n",
    "                vent_df_y['assessment_timepoint'].astype(str).str.zfill(3),\n",
    "            intubation_number = lambda vent_df_y: #assign intubation_number = 1 for all encounters where Encounter_Count >1\n",
    "                vent_df_y['intubation_number'].mask(vent_df_y.Encounter_Count >= 2, 1),\n",
    "            Bhavani_Score = lambda df_y: df_y['sofa_score']+df_y['Bhavani_C'],\n",
    "            Colorado_Score = lambda df_y: df_y['sofa_score']+df_y['Colorado_C']\n",
    "        )\n",
    "    .drop_duplicates(subset=[\"seq_num\"])\n",
    "    .rename(columns={\n",
    "        'seq_num':'EIT',\n",
    "        'intubation_number':'Intubation',\n",
    "        'assessment_timepoint':'Timepoint',\n",
    "        'vent_duration (hours)':'Vent_Duration',\n",
    "        'sofa_score':'SOFA',\n",
    "        'assessment_color':'NY_Score'}\n",
    "        )\n",
    "    .reindex(columns=[\n",
    "        'EIT',\n",
    "        'EncounterID',\n",
    "        'SubjectID',\n",
    "        'Intubation',\n",
    "        'Timepoint',\n",
    "        'Vent_Duration',\n",
    "        'SOFA',\n",
    "        'NY_Score',\n",
    "        'Bhavani_Score',\n",
    "        'Colorado_Score'\n",
    "        ])\n",
    "    #.set_index(['SubjectID', 'Intubation', 'Timepoint'])\n",
    "    .sort_values(by=[\"EIT\"])\n",
    "    #.reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis of Excluded vs Included Subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Encounters:  3720\n",
      "Number of Unique Subjects:  3512\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3720 entries, 0 to 36442\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   EncounterID  3720 non-null   object\n",
      " 1   SubjectID    3720 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "None\n",
      "Number of Unique Encounters:  4604\n",
      "Number of Unique Subjects:  4147\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4605 entries, 0 to 4604\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   seq                    4605 non-null   int64  \n",
      " 1   Encounter_Number       4605 non-null   object \n",
      " 2   SubjectID              4605 non-null   object \n",
      " 3   Race                   4605 non-null   int64  \n",
      " 4   Ethnicity              4319 non-null   float64\n",
      " 5   Sex                    4605 non-null   int64  \n",
      " 6   Discharge_Status       4594 non-null   float64\n",
      " 7   Length_of_Stay (days)  4593 non-null   float64\n",
      " 8   Age_at_Admission       4601 non-null   object \n",
      " 9   Reduced_Race           4605 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(3)\n",
      "memory usage: 359.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##Check for size\n",
    "\n",
    "check_df = (vent_df \n",
    "    .merge(encounter_df, on = ['EncounterID', 'SubjectID'])\n",
    "    .merge(comorbid_df, on = ['EncounterID', 'SubjectID'])\n",
    "    .dropna(subset=[\"ICD_10\"])\n",
    "    .reindex(columns=['EncounterID', 'SubjectID'])\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "print('Number of Unique Encounters: ', check_df['EncounterID'].drop_duplicates().count())\n",
    "print('Number of Unique Subjects: ', check_df['SubjectID'].drop_duplicates().count())\n",
    "print(check_df.info())\n",
    "\n",
    "print('Number of Unique Encounters: ', study_cohort_df['Encounter_Number'].drop_duplicates().count())\n",
    "print('Number of Unique Subjects: ', study_cohort_df['SubjectID'].drop_duplicates().count())\n",
    "print(study_cohort_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Encounters:  3707\n",
      "Number of Unique Subjects:  3512\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3707 entries, 0 to 3706\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   EncounterID       3707 non-null   object  \n",
      " 1   SubjectID         3707 non-null   object  \n",
      " 2   Age               3707 non-null   float64 \n",
      " 3   Race              3061 non-null   object  \n",
      " 4   Ethnicity         3707 non-null   object  \n",
      " 5   Sex               3707 non-null   object  \n",
      " 6   InitialSOFA       3707 non-null   int64   \n",
      " 7   StayLength        3707 non-null   float64 \n",
      " 8   CCS_raw           3707 non-null   int64   \n",
      " 9   CCS_age           3707 non-null   int64   \n",
      " 10  CCS_Colorado      3707 non-null   int64   \n",
      " 11  ECI_raw           3707 non-null   int64   \n",
      " 12  LE                3707 non-null   float64 \n",
      " 13  Cho_LE            3707 non-null   float64 \n",
      " 14  COVID_Status      3707 non-null   int8    \n",
      " 15  Discharge_Status  3707 non-null   int64   \n",
      " 16  Intubation        3707 non-null   int64   \n",
      " 17  NY_Score          3707 non-null   int8    \n",
      " 18  Bhavani_Score     3707 non-null   int64   \n",
      " 19  Colorado_Score    3707 non-null   int64   \n",
      " 20  Protocol          3707 non-null   object  \n",
      " 21  Survived          3707 non-null   int8    \n",
      " 22  Age_Group         3707 non-null   category\n",
      " 23  Count             3707 non-null   int64   \n",
      "dtypes: category(1), float64(4), int64(10), int8(3), object(6)\n",
      "memory usage: 593.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nexcluded_IDs = (excluded_IDs \\n    .merge(check_2, how='outer', indicator=True)\\n    .reindex(columns=['SubjectID', 'EncounterID', '_merge'])\\n)\\nexcluded_IDs = excluded_IDs[excluded_IDs._merge != 'both'].reindex(columns=['SubjectID', 'Encounter_Number'])\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_pull_df = pd.read_pickle(\"encounters.pkl\")\n",
    "print('Number of Unique Encounters: ', database_pull_df['EncounterID'].drop_duplicates().count())\n",
    "print('Number of Unique Subjects: ', database_pull_df['SubjectID'].drop_duplicates().count())\n",
    "print(database_pull_df.info())\n",
    "\n",
    "check_2 = check_df.merge(database_pull_df, on=[\"SubjectID\", \"EncounterID\"], how=\"outer\", indicator=True)\n",
    "check_2 = check_2[check_2._merge != 'both']\n",
    "\n",
    "#Compile list of error SubjectIDs (i.e. excluded)\n",
    "excluded_IDs = (study_cohort_df\n",
    "    .rename(columns = {\"Encounter_Number\": \"EncounterID\"})\n",
    "    .reindex(columns = [\"SubjectID\", \"EncounterID\"])\n",
    "    .merge(database_pull_df, how='outer', indicator=True)\n",
    "    .rename(columns = {\"EncounterID\":\"Encounter_Number\"})\n",
    "#    .reindex(columns=['EncounterID', '_merge'])\n",
    ")\n",
    "excluded_IDs = excluded_IDs[excluded_IDs._merge != 'both'].reindex(columns=['SubjectID', 'Encounter_Number'])\n",
    "'''\n",
    "excluded_IDs = (excluded_IDs \n",
    "    .merge(check_2, how='outer', indicator=True)\n",
    "    .reindex(columns=['SubjectID', 'EncounterID', '_merge'])\n",
    ")\n",
    "excluded_IDs = excluded_IDs[excluded_IDs._merge != 'both'].reindex(columns=['SubjectID', 'Encounter_Number'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 898 entries, 0 to 898\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   EncounterID       898 non-null    object \n",
      " 1   SubjectID         898 non-null    object \n",
      " 2   Age               894 non-null    object \n",
      " 3   Race              898 non-null    int64  \n",
      " 4   Ethnicity         832 non-null    float64\n",
      " 5   Sex               898 non-null    int64  \n",
      " 6   InitialSOFA       0 non-null      float64\n",
      " 7   StayLength        886 non-null    float64\n",
      " 8   Discharge_Status  887 non-null    float64\n",
      " 9   COVID_Status      860 non-null    float64\n",
      " 10  CCS_raw           888 non-null    float64\n",
      " 11  CCS_age           888 non-null    float64\n",
      " 12  CCS_Colorado      888 non-null    float64\n",
      " 13  ECI_raw           888 non-null    float64\n",
      " 14  Life_Exp          894 non-null    float64\n",
      " 15  Cho_Tier          888 non-null    object \n",
      " 16  Cho_LE            886 non-null    float64\n",
      "dtypes: float64(11), int64(2), object(4)\n",
      "memory usage: 126.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excluded_df = (study_cohort_df#[['SubjectID', 'Encounter_Number', 'Discharge_Status', 'Length_of_Stay (days)', 'Age_at_Admission']]\n",
    "    .merge(excluded_IDs, on=[\"SubjectID\", \"Encounter_Number\"])\n",
    "    .merge(covid_df[[\"SubjectID\", \"COVID_POSITIVE_N3C_Phenotype\"]], on=\"SubjectID\", how='left')\n",
    "    .merge(encounter_le[['Encounter_Number','Life_Exp','Cho_Tier', 'Cho_LE']], on='Encounter_Number', how=\"left\") #bring in Life Expectancy and Cho-Adjusted LE\n",
    "    .rename(columns={ \n",
    "        \"Encounter_Number\": 'EncounterID',\n",
    "        'Length_of_Stay (days)': 'StayLength', \n",
    "        'COVID_POSITIVE_N3C_Phenotype': 'COVID_Status',\n",
    "        'Age_at_Admission': 'Age'\n",
    "        })\n",
    "    .sort_values(by=\"EncounterID\")\n",
    "    .merge(encounter_comorbid[['EncounterID', 'CCS_raw', 'CCS_age', 'CCS_Colorado','ECI_raw']], on='EncounterID', how=\"left\") #bring in Charlson and Elixhauser scores\n",
    "    .reindex(columns=[\n",
    "        'EncounterID',\n",
    "        'SubjectID',\n",
    "        'Age',\n",
    "        'Race',\n",
    "        'Ethnicity',\n",
    "        'Sex',\n",
    "        'InitialSOFA', #Column is entirely NaN, but needs to exist for processing by calculators.ipynb\n",
    "        'StayLength',\n",
    "        'Discharge_Status',\n",
    "        'COVID_Status',\n",
    "        'CCS_raw',\n",
    "        'CCS_age',\n",
    "        'CCS_Colorado',\n",
    "        'ECI_raw',\n",
    "        'Life_Exp', \n",
    "        'Cho_Tier', \n",
    "        'Cho_LE']\n",
    "        )\n",
    "    .drop_duplicates()\n",
    "\n",
    ")\n",
    "\n",
    "print (excluded_df.info())\n",
    "\n",
    "excluded_df.to_pickle(\"excluded_raw.pkl\")\n",
    "\n",
    "## 'CCS_Colorado', 'CCS_age', 'Cho_LE', 'InitialSOFA'\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del included_1, included_2, included_3, included_3_merge, included, study_cohort_df, admission_df\n",
    "\n",
    "del encounter_counts, encounter_df, intubation_counts, insurance_xl_df, blis_df, covid_df\n",
    "\n",
    "del vent_encounter_1_df, vent_encounter_multi_df, vent_encounter_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd5d0a8147fa3de6a86df2ea899fcd7eaa3fdbc819680b9fed256305e6d97914"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
