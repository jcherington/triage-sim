{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b0c451",
   "metadata": {},
   "source": [
    "# Preliminaries and Dataframe Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7937a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'datasci' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n datasci ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "#Formatting\n",
    "plt.rcParams['font.family'] = 'Times New Roman'  # Set plt shows font to Times New Roman\n",
    "plt.rcParams['axes.grid'] = True  # Ensure line graphs display on graphs\n",
    "sns.set_palette(sns.color_palette('Accent')) #set color palette to a nice seaborn style https://seaborn.pydata.org/tutorial/color_palettes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6e8cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3707 entries, 0 to 3706\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   EncounterID       3707 non-null   object  \n",
      " 1   SubjectID         3707 non-null   object  \n",
      " 2   Age               3707 non-null   float64 \n",
      " 3   Race              3707 non-null   object  \n",
      " 4   Ethnicity         3707 non-null   object  \n",
      " 5   Sex               3707 non-null   object  \n",
      " 6   InitialSOFA       3707 non-null   int64   \n",
      " 7   StayLength        3707 non-null   float64 \n",
      " 8   LE                3707 non-null   float64 \n",
      " 9   Cho_LE            3707 non-null   float64 \n",
      " 10  COVID_Status      3707 non-null   int8    \n",
      " 11  Discharge_Status  3707 non-null   int64   \n",
      " 12  Intubation        3707 non-null   int64   \n",
      " 13  NY_Score          3707 non-null   int8    \n",
      " 14  Bhavani_Score     3707 non-null   int64   \n",
      " 15  Colorado_Score    3707 non-null   int64   \n",
      " 16  Protocol          3707 non-null   object  \n",
      " 17  Survived          3707 non-null   int8    \n",
      " 18  Age_Group         3707 non-null   category\n",
      " 19  Count             3707 non-null   int64   \n",
      " 20  Run               3707 non-null   int64   \n",
      " 21  Capacity          3707 non-null   int64   \n",
      " 22  Allocated         3707 non-null   int64   \n",
      " 23  Baseline_Surv     3707 non-null   int8    \n",
      "dtypes: category(1), float64(4), int64(9), int8(4), object(6)\n",
      "memory usage: 568.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Import Encounters from Database Query\n",
    "df_baseline = pd.read_pickle(\"encounters.pkl\").assign(Run = 1, Capacity = 1, Allocated = 1, Baseline_Surv = lambda df_: df_['Survived'])\n",
    "print(df_baseline.info())\n",
    "\n",
    "df_demographics = (df_baseline\n",
    "    .assign(Baseline_Surv = lambda df_baseline: df_baseline['Survived']) #create column for whether individual survived at 100% capacity / with ventilator support\n",
    "    .reindex(columns = [\n",
    "    'EncounterID',\n",
    "    'Race',\n",
    "    'Sex',\n",
    "    'Age_Group',\n",
    "    'COVID_Status',\n",
    "    'Baseline_Surv',\n",
    "    'LE',\n",
    "    'Cho_LE']\n",
    "    )\n",
    ")\n",
    "\n",
    "df_50_NY = pd.read_csv('MC_NY_50.csv', converters={'EncounterID':str}).assign(Protocol = 'NY SOFA').merge(df_demographics, on=['EncounterID'])\n",
    "df_50_Age = pd.read_csv('MC_Age_50.csv', converters={'EncounterID':str}).assign(Protocol = 'Age').merge(df_demographics, on=['EncounterID', 'Age_Group'])\n",
    "df_50_Lott = pd.read_csv('MC_Lott_50.csv', converters={'EncounterID':str}).assign(Protocol = 'Lottery').merge(df_demographics, on=['EncounterID'])\n",
    "df_50_Bhavani = pd.read_csv('MC_Bhavani_50.csv', converters={'EncounterID':str}).assign(Protocol = 'Bhavani').merge(df_demographics, on=['EncounterID'])\n",
    "df_50_Colorado = pd.read_csv('MC_Colorado_50.csv', converters={'EncounterID':str}).assign(Protocol = 'Colorado').merge(df_demographics, on=['EncounterID'])\n",
    "df_50_sofa = pd.read_csv('MC_sofa_50.csv', converters={'EncounterID':str}).assign(Protocol = 'Pure SOFA').merge(df_demographics, on=['EncounterID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc7af5e",
   "metadata": {},
   "source": [
    "TO-DO\n",
    "- Create list of columns for neat aggregation of Raw and Age-Adjusted Stats\n",
    "- Create FPR and FNR columns (i.e. if allocated =1 and Baseline_Surv = 0, then FP, if allocated = 0 and Baseline_Surv=1 then FN)\n",
    "- Adjust the Table 2 and Table 3 code to conform to the new summary stats.csv\n",
    "- Generate new scatter plot for Lives Saved Rate by Life Years Saved Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bcd9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import chi2\n",
    "\n",
    "#DEFINE Raw Stats Calculator#\n",
    "def get_raw_stats(df_, groups, alpha=0.05):\n",
    "    return (df_\n",
    "        .fillna(0)\n",
    "        .assign(Exp_Surv = lambda df_: df_['Baseline_Surv']*df_['Capacity'], #multiples each individual patient (i.e. 1 or 0) by capacity (e.g. 0.5) to get expected survival in agg.\n",
    "                FN = lambda df_: df_['Baseline_Surv'].mask(df_['Allocated'] == 1, 0), #return baseline, then overwrite with 0 if allocated=1\n",
    "                FP = lambda df_: df_['Allocated'].mask(df_['Baseline_Surv'] == 1, 0) #return allocated, then overwrite with 0 if baseline=1\n",
    "            )          \n",
    "        .groupby(groups, as_index=True)\n",
    "        .agg(Pop_N=pd.NamedAgg(column=\"Survived\", aggfunc=\"count\"),\n",
    "             Exp_Surv=pd.NamedAgg(column=\"Exp_Surv\", aggfunc=\"sum\"),\n",
    "             Allocated=pd.NamedAgg(column=\"Allocated\", aggfunc=\"sum\"),\n",
    "             Survived=pd.NamedAgg(column=\"Survived\", aggfunc=\"sum\"),\n",
    "             FN=pd.NamedAgg(column=\"FN\", aggfunc=\"sum\"),\n",
    "             FP=pd.NamedAgg(column=\"FP\", aggfunc=\"sum\")\n",
    "             )\n",
    "        .reset_index()\n",
    "        #Calculate Lives Saved and Allocation Rate\n",
    "        .assign(Lives_Saved = lambda df_0: df_0['Survived']-df_0['Exp_Surv'],\n",
    "                A_rate = lambda df_0: df_0['Allocated'] / df_0['Pop_N']\n",
    "            )\n",
    "        .assign(A_rate_CI_lo = lambda df_2: (0.5*chi2.ppf(\n",
    "                    alpha/2, #alpha\n",
    "                    2*df_2['Allocated'] #shape (N.B.: if shape is zero, then result should be defined as zero)\n",
    "                    )) / df_2['Pop_N'],\n",
    "                A_rate_CI_hi = lambda df_2: (0.5*chi2.ppf(\n",
    "                    1 - alpha/2, #alpha\n",
    "                    2*(df_2['Allocated']+1) #shape (N.B.: if shape is zero, then result should be defined as zero)\n",
    "                    )) / df_2['Pop_N']\n",
    "            )\n",
    "        #Calculate Survival Rate (by first calculating death rate)\n",
    "        .assign(Deaths = lambda df_0: df_0['Pop_N'] - df_0['Survived'])\n",
    "        .assign(D_rate = lambda df_1: df_1['Deaths'] / df_1['Pop_N'])\n",
    "        .assign(D_rate_CI_lo = lambda df_2: (0.5*chi2.ppf(\n",
    "                    alpha/2, #alpha\n",
    "                    2*df_2['Deaths'] #shape (N.B.: if shape is zero, then result should be defined as zero)\n",
    "                    )) / df_2['Pop_N'],\n",
    "                D_rate_CI_hi = lambda df_2: (0.5*chi2.ppf(\n",
    "                    1 - alpha/2, #alpha\n",
    "                    2*(df_2['Deaths']+1) #shape (N.B.: if shape is zero, then result should be defined as zero)\n",
    "                    )) / df_2['Pop_N']\n",
    "            )\n",
    "        .assign(S_rate = lambda df_3: 1-df_3['D_rate'],\n",
    "                S_rate_CI_lo = lambda df_3: 1-df_3['D_rate_CI_hi'],\n",
    "                S_rate_CI_hi = lambda df_3: 1-df_3['D_rate_CI_lo'])\n",
    "        #Calculate FNR, FPR and Lives Saved per Patient\n",
    "        .assign(FN_rate = lambda df_0: df_0['FN']/(df_0['Pop_N']-df_0['Allocated']),\n",
    "                FP_rate = lambda df_0: df_0['FP']/df_0['Allocated'],\n",
    "                LS_rate = lambda df_0: df_0['Lives_Saved']/df_0['Pop_N']\n",
    "            )\n",
    "        #Cleanup\n",
    "        .drop(['Deaths', 'D_rate', 'D_rate_CI_hi', 'D_rate_CI_lo'], axis=1)\n",
    "        .round(4)\n",
    "        .set_index(groups)\n",
    "    )\n",
    "\n",
    "#DEFINE Age-Adjusted Calculator#\n",
    "def get_age_adjusted_stats(df_, groups, alpha=0.05):\n",
    "    \n",
    "    std_pop = pd.DataFrame({\n",
    "    'Age_Group': ['<25', '25-34', '35-44', '45-54', '55-64', '65-74', '75-84', '>85'],\n",
    "    'Std_Pop': [(0.013818 + 0.055317 + 0.145565 + 0.138646), 0.135573, 0.162613, 0.134834, 0.087247, 0.066037, 0.044842, 0.015508]})\n",
    "\n",
    "    if ('Age_Group' in groups): \n",
    "        groups_age = groups\n",
    "    else:\n",
    "        groups_age = groups + ['Age_Group']\n",
    "\n",
    "    return (df_\n",
    "        .fillna(0)\n",
    "        .assign(Exp_Surv = lambda df_: df_['Baseline_Surv']*df_['Capacity'], #multiples each individual patient (i.e. 1 or 0) by capacity (e.g. 0.5) to get expected survival in agg.\n",
    "                FN = lambda df_: df_['Baseline_Surv'].mask(df_['Allocated'] == 1, 0), #return baseline, then overwrite with 0 if allocated=1\n",
    "                FP = lambda df_: df_['Allocated'].mask(df_['Baseline_Surv'] == 1, 0) #return allocated, then overwrite with 0 if baseline=1\n",
    "            )\n",
    "        #calculate population totals for each age group (additionally sliced by other variables, e.g. protocol, run, race)\n",
    "        .groupby(groups_age, as_index=True) #originally false\n",
    "        .agg(Pop_N=pd.NamedAgg(column=\"Survived\", aggfunc=\"count\"),\n",
    "             Exp_Surv=pd.NamedAgg(column=\"Exp_Surv\", aggfunc=\"sum\"),\n",
    "             Allocated=pd.NamedAgg(column=\"Allocated\", aggfunc=\"sum\"),\n",
    "             Survived=pd.NamedAgg(column=\"Survived\", aggfunc=\"sum\"),\n",
    "             FN=pd.NamedAgg(column=\"FN\", aggfunc=\"sum\"),\n",
    "             FP=pd.NamedAgg(column=\"FP\", aggfunc=\"sum\")             \n",
    "             )\n",
    "        .reset_index()\n",
    "        .merge(std_pop, on='Age_Group') #bring in standard pop for age-adjustment\n",
    "        .assign(Std_Pop = lambda df_0: df_0['Std_Pop'].mask(df_0['Pop_N'] == 0, 0), #zero out Std_Pop for each sub-group age-band where sub-group has no subjects (i.e. no AIAN in <25)\n",
    "                Deaths = lambda df_0: df_0['Pop_N'] - df_0['Survived'],\n",
    "                Lives_Saved = lambda df_0: df_0['Survived']-df_0['Exp_Surv']\n",
    "            )\n",
    "        #Calculate Age-Adj Deaths and Variance for each age-group\n",
    "        .assign(Age_Adj_D_rate = lambda df_1: (df_1['Deaths']/df_1['Pop_N']) * df_1['Std_Pop'], #calculate the age-adjusted rate (https://seer.cancer.gov/seerstat/WebHelp/Rate_Algorithms.htm)\n",
    "                #Age_Adj_D_var = lambda df_1: (df_1['Std_Pop']**2)*(df_1['Deaths']/(df_1['Pop_N']**2)), ## OLD VERSION, unclear why used.\n",
    "                Age_Adj_D_var = lambda df_1: df_1['Deaths']*((df_1['Std_Pop']/df_1['Pop_N'])**2), ## SEER STAT version https://seer.cancer.gov/seerstat/WebHelp/Rate_Algorithms.htm\n",
    "                #variance for each age_group to be summed for total variance of Race (see WA Health doc) https://doh.wa.gov/sites/default/files/legacy/Documents/1500//ConfIntGuide.pdf\n",
    "         ## Calculate Age-Adjusted FNR and FPR for each age-group\n",
    "                Age_Adj_FN_rate = lambda df_1: (df_1['FN']/(df_1['Pop_N']-df_1['Allocated'])) * df_1['Std_Pop'], #first converts LS into an LS-rate, then multiples by proportion of std pop in that group\n",
    "                Age_Adj_FP_rate = lambda df_1: (df_1['FP']/df_1['Allocated']) * df_1['Std_Pop'],\n",
    "        ## Calculate Age-Adjusted Lives Saved Rate for each age group\n",
    "                Age_Adj_LS_rate = lambda df_1: (df_1['Lives_Saved']/df_1['Pop_N']) * df_1['Std_Pop'], #first converts LS into an LS-rate, then multiples by proportion of std pop in that group\n",
    "            )\n",
    "        #Assign the w variables to each Age_Group (and other groupings)\n",
    "        .assign(w_i = lambda df_1: df_1['Std_Pop']/df_1['Pop_N']) #calc pop weight for each Age_Group and Race (use max for Fay and Freur, and avg for Tiwari mod)\n",
    "        .assign(w_max = lambda df_2: df_2.groupby(groups)['w_i'].transform('max')) #find max pop weight for Fay and Freur CIs (note use of transform, see here https://stackoverflow.com/questions/35640364/python-pandas-max-value-in-a-group-as-a-new-column\n",
    "        #Collapse the age-groups to calculate total age-adjusted deaths/lives saved.\n",
    "        .groupby(groups, as_index=False).sum(numeric_only=True)\n",
    "        .assign(w_max = lambda df_3: df_3['w_max']/len(df_.groupby('Age_Group').count())) #divide sum of max pop weights by number of age-groups - i.e. 8 (to re-idnetify the max pop weight for Race)\n",
    "        ## Calculate Fay-Feur CIs for Age-Adjusted Death Rates\n",
    "        .assign(Age_Adj_D_rate_CI_lo = lambda df_3: \n",
    "                    (df_3['Age_Adj_D_var'])/(2*df_3['Age_Adj_D_rate']) *\n",
    "                    chi2.ppf(alpha/2, #alpha \n",
    "                        (2*df_3['Age_Adj_D_rate']**2)/df_3['Age_Adj_D_var']), #shape\n",
    "                Age_Adj_D_rate_CI_hi = lambda df_3: \n",
    "                    ((df_3['Age_Adj_D_var']+df_3['w_max']**2)/(2*(df_3['Age_Adj_D_rate']+df_3['w_max']))) *\n",
    "                    chi2.ppf(1-alpha/2, # alpha\n",
    "                        (2*(df_3['Age_Adj_D_rate']+df_3['w_max'])**2)/(df_3['Age_Adj_D_var']+df_3['w_max']**2)) #shape\n",
    "            )\n",
    "        #Calculate Age-Adjusted Survival Rates and CIs (as inverse of AA Death Rates and CIs)\n",
    "        .assign(Age_Adj_S_rate = lambda df_4: 1-df_4['Age_Adj_D_rate'],\n",
    "                Age_Adj_S_rate_CI_lo = lambda df_4: 1-df_4['Age_Adj_D_rate_CI_hi'],\n",
    "                Age_Adj_S_rate_CI_hi = lambda df_4: 1-df_4['Age_Adj_D_rate_CI_lo'],\n",
    "            )\n",
    "        .drop(['Survived', 'Allocated', 'FN', 'FP', 'Exp_Surv', 'Lives_Saved', 'Pop_N', 'Deaths','Std_Pop','w_i', 'w_max', 'Age_Adj_D_var', 'Age_Adj_D_rate', 'Age_Adj_D_rate_CI_hi', 'Age_Adj_D_rate_CI_lo'], axis=1)\n",
    "        .round(4)\n",
    "        .set_index(groups)\n",
    "    )\n",
    "\n",
    "#df_test = get_raw_stats(df_50_sofa, ['Protocol', 'Run', 'Race']).reset_index()\n",
    "#df_test = (pd.concat((get_raw_stats(df_50_sofa, ['Protocol', 'Run', 'Race']), get_age_adjusted_stats(df_50_sofa, ['Protocol', 'Run', 'Race'])), axis=1).reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143f13bf",
   "metadata": {},
   "source": [
    "NOTE: \n",
    "- Misallocation costs of life years\n",
    "    - False Negative Life Expectancies are \"years of life lost to allocation denials\" (i.e. if we had a perfect allocation system we would have retained those years of life)\n",
    "    - False Positive Life Expectancies are \"years of life that ????\" - very hard to parse..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e250547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n        ##Calculate , by calculating AA_YLL, AA_Total_LE, and AA_Exp_LE_Cho\\n        .assign(##Calculate CIs for Age_Adj_YLL_Cho\\n                Age_Adj_YLL_Cho_rate_CI_lo = lambda df_3: \\n                    (df_3['Age_Adj_YLL_Cho_var'])/(2*df_3['Age_Adj_YLL_Cho_rate']) *\\n                    chi2.ppf(alpha/2, #alpha \\n                        (2*df_3['Age_Adj_YLL_Cho_rate']**2)/df_3['Age_Adj_YLL_Cho_var']), #shape\\n                Age_Adj_YLL_Cho_rate_CI_hi = lambda df_3: \\n                    ((df_3['Age_Adj_YLL_Cho_var']+df_3['w_max']**2)/(2*(df_3['Age_Adj_YLL_Cho_rate']+df_3['w_max']))) *\\n                    chi2.ppf(1-alpha/2, # alpha\\n                        (2*(df_3['Age_Adj_YLL_Cho_rate']+df_3['w_max'])**2)/(df_3['Age_Adj_YLL_Cho_var']+df_3['w_max']**2)), #shape\\n                ##Calculate CIs for Age_Adj_Total_LE_Cho\\n                Age_Adj_LE_Total_Cho_rate_CI_lo = lambda df_3: \\n                    (df_3['Age_Adj_LE_Total_Cho_var'])/(2*df_3['Age_Adj_LE_Total_Cho_rate']) *\\n                    chi2.ppf(alpha/2, #alpha \\n                        (2*df_3['Age_Adj_LE_Total_Cho_rate']**2)/df_3['Age_Adj_LE_Total_Cho_var']), #shape\\n                Age_Adj_LE_Total_Cho_rate_CI_hi = lambda df_3: \\n                    ((df_3['Age_Adj_LE_Total_Cho_var']+df_3['w_max']**2)/(2*(df_3['Age_Adj_LE_Total_Cho_rate']+df_3['w_max']))) *\\n                    chi2.ppf(1-alpha/2, # alpha\\n                        (2*(df_3['Age_Adj_LE_Total_Cho_rate']+df_3['w_max'])**2)/(df_3['Age_Adj_LE_Total_Cho_var']+df_3['w_max']**2)), #shape\\n                ##Calculate CIs for Age_Adj_Exp_LE_Cho\\n                Age_Adj_Exp_LE_Cho_rate_CI_lo = lambda df_3: \\n                    (df_3['Age_Adj_Exp_LE_Cho_var'])/(2*df_3['Age_Adj_Exp_LE_Cho_rate']) *\\n                    chi2.ppf(alpha/2, #alpha \\n                        (2*df_3['Age_Adj_Exp_LE_Cho_rate']**2)/df_3['Age_Adj_Exp_LE_Cho_var']), #shape\\n                Age_Adj_Exp_LE_Cho_rate_CI_hi = lambda df_3: \\n                    ((df_3['Age_Adj_Exp_LE_Cho_var']+df_3['w_max']**2)/(2*(df_3['Age_Adj_Exp_LE_Cho_rate']+df_3['w_max']))) *\\n                    chi2.ppf(1-alpha/2, # alpha\\n                        (2*(df_3['Age_Adj_Exp_LE_Cho_rate']+df_3['w_max'])**2)/(df_3['Age_Adj_Exp_LE_Cho_var']+df_3['w_max']**2)), #shape\\n            )\\n        \""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.distributions import chi2\n",
    "\n",
    "#DEFINE Cormorbidity Adjusted YLL Calculator#\n",
    "def get_Cho_YLS_stats(df_, groups, alpha=0.05):\n",
    "    return (df_\n",
    "        .fillna(0)\n",
    "        .assign(YLL_Cho = lambda df_: df_['Cho_LE'].mask(df_['Survived'] == 1, 0), ## if survived then zero, otherwise retain life expectancy so that we sum to get YLLs.\n",
    "                Exp_LE_Cho = lambda df_: df_['Baseline_Surv']*df_['Cho_LE']*df_['Capacity'], # if patient would have survived with ventilator then their Cho_LE x Capacity (e.g. 0.5), otherwise 0 (if deceased even with ventilator)\n",
    "                FN_LE_Cho = lambda df_: (df_['Baseline_Surv']*df_['Cho_LE']).mask(df_['Allocated'] == 1, 0), #return baseline*Cho_LE, then overwrite with 0 if allocated=1\n",
    "                FP_LE_Cho = lambda df_: (df_['Allocated']*df_['Cho_LE']).mask(df_['Baseline_Surv'] == 1, 0) #return allocated*Cho_LE, then overwrite with 0 if baseline=1\n",
    "            )\n",
    "        .groupby(groups, as_index=False)\n",
    "        .agg(Pop_N=pd.NamedAgg(column=\"Cho_LE\", aggfunc=\"count\"),\n",
    "             Allocated=pd.NamedAgg(column=\"Allocated\", aggfunc=\"sum\"),\n",
    "             LE_Total_Cho=pd.NamedAgg(column=\"Cho_LE\", aggfunc=\"sum\"), #Total life expectancy for everyone, regardless of survival in 100% baseline\n",
    "             Exp_LE_Cho=pd.NamedAgg(column=\"Exp_LE_Cho\", aggfunc=\"sum\"), #Total life expectancy for everyone who did survive in 100% baseline, multiplied by capacity (i.e. 0.5)\n",
    "             YLL_Cho=pd.NamedAgg(column=\"YLL_Cho\", aggfunc=\"sum\"), #Total life expectancy (lost) of all those who did not survive (in simulation)\n",
    "             FN_LE_Cho=pd.NamedAgg(column=\"FN_LE_Cho\", aggfunc=\"sum\"), #Total life expectancy for everyone who would have survived, but was not allocated (false negatives)\n",
    "             FP_LE_Cho=pd.NamedAgg(column=\"FP_LE_Cho\", aggfunc=\"sum\") #Total life expectancy for everyone who did NOT survive, but was allocated (false positives)\n",
    "             )\n",
    "        #Calculate Cho YLL CIs\n",
    "        #.assign(YLL_Cho_CI_lo = lambda df_2: (0.5*chi2.ppf(\n",
    "        #            alpha/2, #alpha\n",
    "        #            2*df_2['YLL_Cho'] #shape (N.B.: if shape is zero, then result should be defined as zero)\n",
    "        #            )),\n",
    "        #        YLL_Cho_CI_hi = lambda df_2: (0.5*chi2.ppf(\n",
    "        #            1 - alpha/2, #alpha\n",
    "        #            2*(df_2['YLL_Cho']+1) #shape (N.B.: if shape is zero, then result should be defined as zero)\n",
    "        #            ))\n",
    "        #    )\n",
    "        #Calculate Cho YLS (i.e. life years over Exp_LE that were \"saved\" by the protocol)\n",
    "        .assign(YLS_Cho = lambda df_1: (df_1['LE_Total_Cho']-df_1['YLL_Cho'])-df_1['Exp_LE_Cho'])\n",
    "        .assign(YLS_Cho_rate = lambda df_2: df_2['YLS_Cho']/df_2['Pop_N'])\n",
    "        .assign(YLS_Cho_CI_lo = lambda df_2: (0.5*chi2.ppf(\n",
    "                    alpha/2, #alpha\n",
    "                    2*df_2['YLS_Cho'] #shape (N.B.: if shape is zero, then result should be defined as zero)\n",
    "                    )),\n",
    "                YLS_Cho_CI_hi = lambda df_2: (0.5*chi2.ppf(\n",
    "                    1 - alpha/2, #alpha\n",
    "                    2*(df_2['YLS_Cho']+1) #shape (N.B.: if shape is zero, then result should be defined as zero)\n",
    "                    ))\n",
    "            )\n",
    "        #Calculate FNR and FPR (i.e. how many years of life lost to errors per patient was not allocated (FN) OR patient who was allocated (FP))\n",
    "        .assign(FNR_LE_Cho = lambda df_0: df_0['FN_LE_Cho']/(df_0['Pop_N']-df_0['Allocated']),\n",
    "                FPR_LE_Cho = lambda df_0: df_0['FP_LE_Cho']/df_0['Allocated']\n",
    "            )\n",
    "        #.drop(['Pop_N','Allocated'], axis=1)\n",
    "        .round(4) #round all number to two decimal places\n",
    "        .set_index(groups)\n",
    "    )\n",
    "\n",
    "#DEFINE Age-Adjusted Comordity-Adjusted YLL Calculator#\n",
    "def get_age_adjusted_Cho_YLS_stats(df_, groups, alpha=0.05):\n",
    "    \n",
    "    std_pop = pd.DataFrame({\n",
    "    'Age_Group': ['<25', '25-34', '35-44', '45-54', '55-64', '65-74', '75-84', '>85'],\n",
    "    'Std_Pop': [(0.013818 + 0.055317 + 0.145565 + 0.138646), 0.135573, 0.162613, 0.134834, 0.087247, 0.066037, 0.044842, 0.015508]})\n",
    "\n",
    "    if ('Age_Group' in groups): \n",
    "        groups_age = groups\n",
    "    else:\n",
    "        groups_age = groups + ['Age_Group']\n",
    "\n",
    "    return (df_\n",
    "        .fillna(0)\n",
    "        .assign(YLL_Cho = lambda df_0: df_0['Cho_LE'].mask(df_0['Survived'] == 1, 0),  ## if survived then zero, otherwise retain life expectancy so that we sum to get YLLs.\n",
    "                Exp_LE_Cho = lambda df_: df_['Baseline_Surv']*df_['Cho_LE']*df_['Capacity'], # Capacity x Cho_LE if patient would have survived with ventilator, otherwise 0 (if deceased even with ventilator)\n",
    "                FN_LE_Cho = lambda df_: (df_['Baseline_Surv']*df_['Cho_LE']).mask(df_['Allocated'] == 1, 0), #return baseline*Cho_LE, then overwrite with 0 if allocated=1\n",
    "                FP_LE_Cho = lambda df_: (df_['Allocated']*df_['Cho_LE']).mask(df_['Baseline_Surv'] == 1, 0) #return allocated*Cho_LE, then overwrite with 0 if baseline=1\n",
    "            )\n",
    "        .groupby(groups_age, as_index=True)\n",
    "        .agg(Pop_N=pd.NamedAgg(column=\"Cho_LE\", aggfunc=\"count\"),\n",
    "             Allocated=pd.NamedAgg(column=\"Allocated\", aggfunc=\"sum\"),\n",
    "             LE_Total_Cho=pd.NamedAgg(column=\"Cho_LE\", aggfunc=\"sum\"),\n",
    "             Exp_LE_Cho=pd.NamedAgg(column=\"Exp_LE_Cho\", aggfunc=\"sum\"),\n",
    "             YLL_Cho=pd.NamedAgg(column=\"YLL_Cho\", aggfunc=\"sum\"),\n",
    "             FN_LE_Cho=pd.NamedAgg(column=\"FN_LE_Cho\", aggfunc=\"sum\"), #Total life expectancy for everyone who would have survived, but was not allocated (false negatives)\n",
    "             FP_LE_Cho=pd.NamedAgg(column=\"FP_LE_Cho\", aggfunc=\"sum\") #Total life expectancy for everyone who did NOT survive, but was allocated (false positives)\n",
    "             )\n",
    "        .reset_index()\n",
    "        .merge(std_pop, on='Age_Group') #bring in standard pop for age-adjustment\n",
    "        .assign(Std_Pop = lambda df_0: df_0['Std_Pop'].mask(df_0['Pop_N'] == 0, 0)) #zero out Std_Pop for each sub-group age-band where sub-group has no subjects (i.e. no AIAN in <25)\n",
    "        .assign(w_i = lambda df_1: df_1['Std_Pop']/df_1['Pop_N']) #calc pop weight for each Age_Group and Race (use max for Fay and Freur, and avg for Tiwari mod)\n",
    "        .assign(w_max = lambda df_2: df_2.groupby(groups)['w_i'].transform('max')) #find max pop weight for Fay and Freur CIs (note use of transform, see here https://stackoverflow.com/questions/35640364/python-pandas-max-value-in-a-group-as-a-new-column\n",
    "        #Calculate Age-Adjusted Cho YLL and Cho YLS\n",
    "        .assign(Age_Adj_FNR_LE_Cho = lambda df_3: (df_3['FN_LE_Cho']/(df_3['Pop_N']-df_3['Allocated'])) * df_3['Std_Pop'], #first converts FN LE into an FNR of LE, then multiples by proportion of std pop in that group\n",
    "                Age_Adj_FPR_LE_Cho = lambda df_3: (df_3['FP_LE_Cho']/df_3['Allocated']) * df_3['Std_Pop'],    \n",
    "                #Age_Adj_YLS_Cho_rate = lambda df_3: (df_3['YLS_Cho']/df_3['Pop_N']) * df_3['Std_Pop'], #calculate the crude YLS rate per age group, then multiply by std pop weight (https://seer.cancer.gov/seerstat/WebHelp/Rate_Algorithms.htm)\n",
    "                #Age_Adj_YLS_Cho_var = lambda df_3: df_3['YLS_Cho']*((df_3['Std_Pop']/df_3['Pop_N'])**2) #variance for each age_group to be summed for total variance of Race (see WA Health doc)\n",
    "                Age_Adj_YLL_Cho_rate = lambda df_3: (df_3['YLL_Cho']/df_3['Pop_N']) * df_3['Std_Pop'], #calculate the crude YLL rate per age group, then multiply by std pop weight (https://seer.cancer.gov/seerstat/WebHelp/Rate_Algorithms.htm)\n",
    "                #Age_Adj_YLL_Cho_var = lambda df_3: df_3['YLL_Cho']*((df_3['Std_Pop']/df_3['Pop_N'])**2), #variance for each age_group to be summed for total variance for each race (see WA Health doc)\n",
    "                Age_Adj_LE_Total_Cho_rate = lambda df_3: (df_3['LE_Total_Cho']/df_3['Pop_N']) * df_3['Std_Pop'], #calculate the crude YLL rate per age group, then multiply by std pop weight (https://seer.cancer.gov/seerstat/WebHelp/Rate_Algorithms.htm)\n",
    "                #Age_Adj_LE_Total_Cho_var = lambda df_3: df_3['LE_Total_Cho']*((df_3['Std_Pop']/df_3['Pop_N'])**2), #variance for each age_group to be summed for total variance for each race (see WA Health doc)\n",
    "                Age_Adj_Exp_LE_Cho_rate = lambda df_3: (df_3['Exp_LE_Cho']/df_3['Pop_N']) * df_3['Std_Pop'], #calculate the crude YLL rate per age group, then multiply by std pop weight (https://seer.cancer.gov/seerstat/WebHelp/Rate_Algorithms.htm)\n",
    "                #Age_Adj_Exp_LE_Cho_var = lambda df_3: df_3['Exp_LE_Cho']*((df_3['Std_Pop']/df_3['Pop_N'])**2) #variance for each age_group to be summed for total variance for each race (see WA Health doc)\n",
    "            )\n",
    "        .groupby(groups, as_index=False).sum(numeric_only=True)\n",
    "        .assign(w_max = lambda df_3: df_3['w_max']/len(df_.groupby('Age_Group').count())) #was 8 #divide sum of max pop weights by number of age-groups (to re-idnetify the max pop weight for Race)\n",
    "        ##Calculate Age-Adj Years of Life Saved and CIs\n",
    "        .assign(Age_Adj_YLS_Cho_rate = lambda df_0: (df_0['Age_Adj_LE_Total_Cho_rate']-df_0['Age_Adj_YLL_Cho_rate'])-df_0['Age_Adj_Exp_LE_Cho_rate'], #Calculate Raw Cho-adjusted Years of Life Saved for 'groups'\n",
    "                #Age_Adj_YLS_Cho_rate_CI_lo = lambda df_0: (df_0['Age_Adj_LE_Total_Cho_rate_CI_lo']-df_0['Age_Adj_YLL_Cho_rate_CI_lo'])-df_0['Age_Adj_Exp_LE_Cho_rate_CI_lo'],\n",
    "                #Age_Adj_YLS_Cho_rate_CI_hi = lambda df_0: (df_0['Age_Adj_LE_Total_Cho_rate_CI_hi']-df_0['Age_Adj_YLL_Cho_rate_CI_hi'])-df_0['Age_Adj_Exp_LE_Cho_rate_CI_hi'],\n",
    "            )\n",
    "        .drop(['Pop_N','Allocated','LE_Total_Cho','Exp_LE_Cho', 'YLL_Cho','FN_LE_Cho', 'FP_LE_Cho', 'Std_Pop', 'w_i', 'w_max',\n",
    "               'Age_Adj_LE_Total_Cho_rate', 'Age_Adj_YLL_Cho_rate',  'Age_Adj_Exp_LE_Cho_rate',  \n",
    "               #'Age_Adj_LE_Total_Cho_var', 'Age_Adj_YLL_Cho_var', 'Age_Adj_Exp_LE_Cho_var',\n",
    "               ], axis=1)\n",
    "        .round(4) #round all numbers to 4 decimals places\n",
    "        .set_index(groups)\n",
    "    )\n",
    "\n",
    "#df_test = (pd.concat((get_Cho_YLS_stats(df_50_sofa, ['Protocol', 'Run', 'Race']), get_age_adjusted_Cho_YLS_stats(df_50_sofa, ['Protocol', 'Run', 'Race'])), axis=1).reset_index())\n",
    "\n",
    "'''\n",
    "        ##Calculate , by calculating AA_YLL, AA_Total_LE, and AA_Exp_LE_Cho\n",
    "        .assign(##Calculate CIs for Age_Adj_YLL_Cho\n",
    "                Age_Adj_YLL_Cho_rate_CI_lo = lambda df_3: \n",
    "                    (df_3['Age_Adj_YLL_Cho_var'])/(2*df_3['Age_Adj_YLL_Cho_rate']) *\n",
    "                    chi2.ppf(alpha/2, #alpha \n",
    "                        (2*df_3['Age_Adj_YLL_Cho_rate']**2)/df_3['Age_Adj_YLL_Cho_var']), #shape\n",
    "                Age_Adj_YLL_Cho_rate_CI_hi = lambda df_3: \n",
    "                    ((df_3['Age_Adj_YLL_Cho_var']+df_3['w_max']**2)/(2*(df_3['Age_Adj_YLL_Cho_rate']+df_3['w_max']))) *\n",
    "                    chi2.ppf(1-alpha/2, # alpha\n",
    "                        (2*(df_3['Age_Adj_YLL_Cho_rate']+df_3['w_max'])**2)/(df_3['Age_Adj_YLL_Cho_var']+df_3['w_max']**2)), #shape\n",
    "                ##Calculate CIs for Age_Adj_Total_LE_Cho\n",
    "                Age_Adj_LE_Total_Cho_rate_CI_lo = lambda df_3: \n",
    "                    (df_3['Age_Adj_LE_Total_Cho_var'])/(2*df_3['Age_Adj_LE_Total_Cho_rate']) *\n",
    "                    chi2.ppf(alpha/2, #alpha \n",
    "                        (2*df_3['Age_Adj_LE_Total_Cho_rate']**2)/df_3['Age_Adj_LE_Total_Cho_var']), #shape\n",
    "                Age_Adj_LE_Total_Cho_rate_CI_hi = lambda df_3: \n",
    "                    ((df_3['Age_Adj_LE_Total_Cho_var']+df_3['w_max']**2)/(2*(df_3['Age_Adj_LE_Total_Cho_rate']+df_3['w_max']))) *\n",
    "                    chi2.ppf(1-alpha/2, # alpha\n",
    "                        (2*(df_3['Age_Adj_LE_Total_Cho_rate']+df_3['w_max'])**2)/(df_3['Age_Adj_LE_Total_Cho_var']+df_3['w_max']**2)), #shape\n",
    "                ##Calculate CIs for Age_Adj_Exp_LE_Cho\n",
    "                Age_Adj_Exp_LE_Cho_rate_CI_lo = lambda df_3: \n",
    "                    (df_3['Age_Adj_Exp_LE_Cho_var'])/(2*df_3['Age_Adj_Exp_LE_Cho_rate']) *\n",
    "                    chi2.ppf(alpha/2, #alpha \n",
    "                        (2*df_3['Age_Adj_Exp_LE_Cho_rate']**2)/df_3['Age_Adj_Exp_LE_Cho_var']), #shape\n",
    "                Age_Adj_Exp_LE_Cho_rate_CI_hi = lambda df_3: \n",
    "                    ((df_3['Age_Adj_Exp_LE_Cho_var']+df_3['w_max']**2)/(2*(df_3['Age_Adj_Exp_LE_Cho_rate']+df_3['w_max']))) *\n",
    "                    chi2.ppf(1-alpha/2, # alpha\n",
    "                        (2*(df_3['Age_Adj_Exp_LE_Cho_rate']+df_3['w_max'])**2)/(df_3['Age_Adj_Exp_LE_Cho_var']+df_3['w_max']**2)), #shape\n",
    "            )\n",
    "        '''\n",
    "\n",
    "                #Calculate Fay-Feur CIs for Age-Adj, CoMorbid-Adj Years of Life Saved\n",
    "                #Age_Adj_YLS_Cho_rate_CI_lo = lambda df_3: \n",
    "                #    (df_3['Age_Adj_YLS_Cho_var'])/(2*df_3['Age_Adj_YLS_Cho_rate']) *\n",
    "                #    chi2.ppf(alpha/2, #alpha \n",
    "                #        (2*df_3['Age_Adj_YLS_Cho_rate']**2)/df_3['Age_Adj_YLS_Cho_var']), #shape\n",
    "                #Age_Adj_YLS_Cho_rate_CI_hi = lambda df_3: \n",
    "                #    ((df_3['Age_Adj_YLS_Cho_var']+df_3['w_max']**2)/(2*(df_3['Age_Adj_YLS_Cho_rate']+df_3['w_max']))) *\n",
    "                #    chi2.ppf(1-alpha/2, # alpha\n",
    "                #        (2*(df_3['Age_Adj_YLS_Cho_rate']+df_3['w_max'])**2)/(df_3['Age_Adj_YLS_Cho_var']+df_3['w_max']**2)) #shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c5968cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats_LE_TEST =  get_raw_YLL(df_50_NY, ['Run','Protocol', 'Race']).reset_index()\n",
    "#stats_LE_TEST = get_age_adjusted_YLL(df_50_NY, ['Run','Protocol', 'Race']).reset_index()\n",
    "df_test =  pd.concat([get_raw_stats(df_50_NY, ['Run','Protocol', 'Race']), get_age_adjusted_stats(df_50_NY, ['Run','Protocol', 'Race']), get_Cho_YLS_stats(df_50_NY, ['Run','Protocol', 'Race']), get_age_adjusted_Cho_YLS_stats(df_50_NY, ['Run','Protocol', 'Race'])], axis=1).reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2423f252",
   "metadata": {},
   "source": [
    "#Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cacf45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Survival Rates #\n",
    "##################\n",
    "stats_overall_50 = pd.concat([\n",
    "    get_raw_stats(df_baseline, ['Protocol', 'Run']),\n",
    "    get_raw_stats(df_50_Lott, ['Protocol', 'Run']),\n",
    "    get_raw_stats(df_50_Age, ['Protocol', 'Run']),\n",
    "    get_raw_stats(df_50_sofa, ['Protocol', 'Run']),\n",
    "    get_raw_stats(df_50_NY, ['Protocol', 'Run']),\n",
    "    get_raw_stats(df_50_Colorado, ['Protocol', 'Run']),\n",
    "    get_raw_stats(df_50_Bhavani, ['Protocol', 'Run'])\n",
    "]).reset_index()\n",
    "\n",
    "stats_race_50 = pd.concat([\n",
    "    pd.concat([get_raw_stats(df_baseline, ['Protocol', 'Run', 'Race']), get_age_adjusted_stats(df_baseline, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Lott, ['Protocol', 'Run', 'Race']), get_age_adjusted_stats(df_50_Lott, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Age, ['Protocol', 'Run', 'Race']), get_age_adjusted_stats(df_50_Age, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_NY, ['Protocol', 'Run', 'Race']), get_age_adjusted_stats(df_50_NY, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_sofa, ['Protocol', 'Run', 'Race']), get_age_adjusted_stats(df_50_sofa, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Colorado, ['Protocol', 'Run', 'Race']), get_age_adjusted_stats(df_50_Colorado, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Bhavani, ['Protocol', 'Run', 'Race']), get_age_adjusted_stats(df_50_Bhavani, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "])\n",
    "\n",
    "stats_age_50 = pd.concat([\n",
    "    pd.concat([get_raw_stats(df_baseline, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_stats(df_baseline, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Lott, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_stats(df_50_Lott, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Age, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_stats(df_50_Age, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_sofa, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_stats(df_50_sofa, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_NY, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_stats(df_50_NY, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Colorado, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_stats(df_50_Colorado, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Bhavani, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_stats(df_50_Bhavani, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index()\n",
    "])\n",
    "\n",
    "stats_COVID_50 = pd.concat([\n",
    "    pd.concat([get_raw_stats(df_baseline, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_stats(df_baseline, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Lott, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_stats(df_50_Lott, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Age, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_stats(df_50_Age, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_sofa, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_stats(df_50_sofa, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_NY, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_stats(df_50_NY, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Colorado, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_stats(df_50_Colorado, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Bhavani, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_stats(df_50_Bhavani, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index()\n",
    "])\n",
    "\n",
    "'''\n",
    "##########################\n",
    "# YLL Sheets #\n",
    "##########################\n",
    "stats_YLL_overall_50 = pd.concat([\n",
    "    get_raw_YLL(df_baseline, ['Protocol', 'Run']),\n",
    "    get_raw_YLL(df_50_Lott, ['Protocol', 'Run']),\n",
    "    get_raw_YLL(df_50_Age, ['Protocol', 'Run']),\n",
    "    get_raw_YLL(df_50_sofa, ['Protocol', 'Run']),\n",
    "    get_raw_YLL(df_50_NY, ['Protocol', 'Run']), \n",
    "    get_raw_YLL(df_50_Colorado, ['Protocol', 'Run']),\n",
    "    get_raw_YLL(df_50_Bhavani, ['Protocol', 'Run'])\n",
    "]).reset_index()\n",
    "\n",
    "stats_YLL_race_50 = pd.concat([\n",
    "    pd.concat([get_raw_YLL(df_baseline, ['Protocol', 'Run', 'Race']), get_age_adjusted_YLL(df_baseline, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_Lott, ['Protocol', 'Run', 'Race']), get_age_adjusted_YLL(df_50_Lott, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_Age, ['Protocol', 'Run', 'Race']), get_age_adjusted_YLL(df_50_Age, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_sofa, ['Protocol', 'Run', 'Race']), get_age_adjusted_YLL(df_50_sofa, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_NY, ['Protocol', 'Run', 'Race']), get_age_adjusted_YLL(df_50_NY, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_Colorado, ['Protocol', 'Run', 'Race']), get_age_adjusted_YLL(df_50_Colorado, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_Bhavani, ['Protocol', 'Run', 'Race']), get_age_adjusted_YLL(df_50_Bhavani, ['Protocol', 'Run', 'Race'])], axis=1).reset_index()\n",
    "])\n",
    "\n",
    "stats_YLL_age_50 = pd.concat([\n",
    "    pd.concat([get_raw_YLL(df_baseline, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_YLL(df_baseline, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_Lott, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_YLL(df_50_Lott, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_Age, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_YLL(df_50_Age, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_sofa, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_YLL(df_50_sofa, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_NY, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_YLL(df_50_NY, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_Colorado, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_YLL(df_50_Colorado, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_Bhavani, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_YLL(df_50_Bhavani, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index()\n",
    "])\n",
    "\n",
    "stats_YLL_COVID_50 = pd.concat([\n",
    "    pd.concat([get_raw_YLL(df_baseline, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_YLL(df_baseline, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_Lott, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_YLL(df_50_Lott, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_Age, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_YLL(df_50_Age, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_sofa, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_YLL(df_50_sofa, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_NY, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_YLL(df_50_NY, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_Colorado, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_YLL(df_50_Colorado, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_YLL(df_50_Bhavani, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_YLL(df_50_Bhavani, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index()\n",
    "])\n",
    "'''\n",
    "##########################\n",
    "# Cho YLL Sheets #\n",
    "##########################\n",
    "stats_Cho_overall_50 = pd.concat([\n",
    "    get_Cho_YLS_stats(df_baseline, ['Protocol', 'Run']),  \n",
    "    get_Cho_YLS_stats(df_50_Lott, ['Protocol', 'Run']), \n",
    "    get_Cho_YLS_stats(df_50_Age, ['Protocol', 'Run']),\n",
    "    get_Cho_YLS_stats(df_50_sofa, ['Protocol', 'Run']),\n",
    "    get_Cho_YLS_stats(df_50_NY, ['Protocol', 'Run']),\n",
    "    get_Cho_YLS_stats(df_50_Colorado, ['Protocol', 'Run']),\n",
    "    get_Cho_YLS_stats(df_50_Bhavani, ['Protocol', 'Run'])\n",
    "]).reset_index()\n",
    "\n",
    "stats_Cho_race_50 = pd.concat([\n",
    "    pd.concat([get_Cho_YLS_stats(df_baseline, ['Protocol', 'Run', 'Race']), get_age_adjusted_Cho_YLS_stats(df_baseline, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_Lott, ['Protocol', 'Run', 'Race']), get_age_adjusted_Cho_YLS_stats(df_50_Lott, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_Age, ['Protocol', 'Run', 'Race']), get_age_adjusted_Cho_YLS_stats(df_50_Age, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_sofa, ['Protocol', 'Run', 'Race']), get_age_adjusted_Cho_YLS_stats(df_50_sofa, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_NY, ['Protocol', 'Run', 'Race']), get_age_adjusted_Cho_YLS_stats(df_50_NY, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_Colorado, ['Protocol', 'Run', 'Race']), get_age_adjusted_Cho_YLS_stats(df_50_Colorado, ['Protocol', 'Run', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_Bhavani, ['Protocol', 'Run', 'Race']), get_age_adjusted_Cho_YLS_stats(df_50_Bhavani, ['Protocol', 'Run', 'Race'])], axis=1).reset_index()\n",
    "])\n",
    "\n",
    "stats_Cho_age_50 = pd.concat([\n",
    "    pd.concat([get_Cho_YLS_stats(df_baseline, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_Cho_YLS_stats(df_baseline, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_Lott, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_Cho_YLS_stats(df_50_Lott, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_Age, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_Cho_YLS_stats(df_50_Age, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_sofa, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_Cho_YLS_stats(df_50_sofa, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_NY, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_Cho_YLS_stats(df_50_NY, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_Colorado, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_Cho_YLS_stats(df_50_Colorado, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_Bhavani, ['Protocol', 'Run', 'Age_Group']), get_age_adjusted_Cho_YLS_stats(df_50_Bhavani, ['Protocol', 'Run', 'Age_Group'])], axis=1).reset_index()\n",
    "])\n",
    "\n",
    "stats_Cho_COVID_50 = pd.concat([\n",
    "    pd.concat([get_Cho_YLS_stats(df_baseline, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_Cho_YLS_stats(df_baseline, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_Lott, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_Cho_YLS_stats(df_50_Lott, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_Age, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_Cho_YLS_stats(df_50_Age, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_sofa, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_Cho_YLS_stats(df_50_sofa, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_NY, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_Cho_YLS_stats(df_50_NY, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_Colorado, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_Cho_YLS_stats(df_50_Colorado, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_Cho_YLS_stats(df_50_Bhavani, ['Protocol', 'Run', 'COVID_Status']), get_age_adjusted_Cho_YLS_stats(df_50_Bhavani, ['Protocol', 'Run', 'COVID_Status'])], axis=1).reset_index()\n",
    "])\n",
    "\n",
    "###Use below to convert Stats to excel sheets####\n",
    "\n",
    "with pd.ExcelWriter(\"MC-50-results-stats.xlsx\") as writer:\n",
    "# use to_excel function and specify the sheet_name and index\n",
    "    # to store the dataframe in specified sheet\n",
    "    stats_overall_50.to_excel(writer, sheet_name=\"Overall\", index=False)\n",
    "    stats_race_50.to_excel(writer, sheet_name=\"Race\", index=False)\n",
    "    stats_age_50.to_excel(writer, sheet_name=\"Age Group\", index=False)\n",
    "    stats_COVID_50.to_excel(writer, sheet_name=\"COVID Status\", index=False)\n",
    "    #stats_YLL_overall_50.to_excel(writer, sheet_name=\"YLL_Overall\", index=False)\n",
    "    #stats_YLL_race_50.to_excel(writer, sheet_name=\"YLL_Race\", index=False)\n",
    "    #stats_YLL_age_50.to_excel(writer, sheet_name=\"YLL_Age_Group\", index=False)\n",
    "    #stats_YLL_COVID_50.to_excel(writer, sheet_name=\"YLL_COVID_Status\", index=False)\n",
    "    stats_Cho_overall_50.to_excel(writer, sheet_name=\"Cho_Overall\", index=False)\n",
    "    stats_Cho_race_50.to_excel(writer, sheet_name=\"Cho_Race\", index=False)\n",
    "    stats_Cho_age_50.to_excel(writer, sheet_name=\"Cho_Age_Group\", index=False)\n",
    "    stats_Cho_COVID_50.to_excel(writer, sheet_name=\"Cho_COVID_Status\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f692144",
   "metadata": {},
   "source": [
    "# AGGREGATION OF RUNS and Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b159b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "#Extract processed results from MC-50-results-stats\n",
    "#####\n",
    "\n",
    "stats_overall_50 = pd.read_excel('MC-50-results-stats.xlsx', sheet_name='Overall')\n",
    "stats_race_50 = pd.read_excel('MC-50-results-stats.xlsx', sheet_name='Race')\n",
    "stats_age_50 = pd.read_excel('MC-50-results-stats.xlsx', sheet_name='Age Group')\n",
    "stats_COVID_50 = pd.read_excel('MC-50-results-stats.xlsx', sheet_name='COVID Status')\n",
    "#stats_YLL_overall_50 = pd.read_excel('MC-50-results-stats.xlsx', sheet_name=\"YLL_Overall\")\n",
    "#stats_YLL_race_50 = pd.read_excel('MC-50-results-stats.xlsx', sheet_name=\"YLL_Race\")\n",
    "#stats_YLL_age_50 = pd.read_excel('MC-50-results-stats.xlsx', sheet_name=\"YLL_Age_Group\")\n",
    "#stats_YLL_COVID_50 = pd.read_excel('MC-50-results-stats.xlsx', sheet_name=\"YLL_COVID_Status\")\n",
    "stats_Cho_overall_50 = pd.read_excel('MC-50-results-stats.xlsx', sheet_name=\"Cho_Overall\")\n",
    "stats_Cho_race_50 = pd.read_excel('MC-50-results-stats.xlsx', sheet_name=\"Cho_Race\")\n",
    "stats_Cho_age_50 = pd.read_excel('MC-50-results-stats.xlsx', sheet_name=\"Cho_Age_Group\")\n",
    "stats_Cho_COVID_50 = pd.read_excel('MC-50-results-stats.xlsx', sheet_name=\"Cho_COVID_Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d88cb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ All Protocols - LS Rate\n",
      "           mean  ci95_lo  ci95_hi\n",
      "Protocol                         \n",
      "Age        28.7     28.6     28.9\n",
      "Baseline    0.0      NaN      NaN\n",
      "Bhavani    18.0     17.8     18.2\n",
      "Colorado   14.7     14.5     14.9\n",
      "Lottery     0.1     -0.1      0.3\n",
      "NY SOFA    13.2     13.0     13.4\n",
      "Pure SOFA  16.7     16.5     16.9\n",
      "------------------------------\n",
      "------------------------------ All Protocols - YLS Rate\n",
      "             mean  ci95_lo  ci95_hi\n",
      "Protocol                           \n",
      "Age        3408.0   3402.0   3413.0\n",
      "Baseline      0.0      NaN      NaN\n",
      "Bhavani    1454.0   1447.0   1461.0\n",
      "Colorado    999.0    992.0   1007.0\n",
      "Lottery       3.0     -6.0     12.0\n",
      "NY SOFA     416.0    407.0    424.0\n",
      "Pure SOFA   839.0    831.0    846.0\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Summary Stats Generator Capacity Levels (Change \"Query\")\n",
    "\n",
    "print('-'*30, 'All Protocols - LS Rate')\n",
    "stats_n_50 = (stats_overall_50\n",
    "    .groupby(['Protocol'])['LS_rate'].agg(['mean', 'std', 'sem'])\n",
    "    .assign(ci95_lo = lambda df_:\n",
    "            df_['mean'] - 1.96* df_['sem'],\n",
    "            ci95_hi = lambda df_:\n",
    "            df_['mean'] + 1.96* df_['sem'],\n",
    "    )\n",
    "    .drop(['std','sem'], axis=1)\n",
    "    .round(4)\n",
    "    .mul(1000) # remove to do per patient, rather than per 1000 patients   \n",
    ")\n",
    "print(stats_n_50)\n",
    "print('-'*30)\n",
    "\n",
    "print('-'*30, 'All Protocols - YLS Rate')\n",
    "stats_Cho_n_50 = (stats_Cho_overall_50\n",
    "    .groupby(['Protocol'])['YLS_Cho_rate'].agg(['mean', 'std', 'sem'])\n",
    "    .assign(ci95_lo = lambda df_:\n",
    "            df_['mean'] - 1.96* df_['sem'],\n",
    "            ci95_hi = lambda df_:\n",
    "            df_['mean'] + 1.96* df_['sem'],\n",
    "    )\n",
    "    .drop(['std','sem'], axis=1)\n",
    "    .round(4)\n",
    "    .mul(1000).round(0) # remove to do per patient, rather than per 1000 patients   \n",
    ")\n",
    "print(stats_Cho_n_50)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b5ae4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ All Protocols - LS Rate\n",
      "                     mean  ci95_lo  ci95_hi\n",
      "Protocol  Race                             \n",
      "Age       >1 Race   207.8    203.0    212.5\n",
      "          AAPI       39.5     36.5     42.6\n",
      "          AIAN      342.3    329.5    355.2\n",
      "          Black      99.9     99.0    100.7\n",
      "          Hispanic  143.4    141.7    145.1\n",
      "          Unknown    56.8     55.1     58.5\n",
      "          White       4.3      4.0      4.6\n",
      "Baseline  >1 Race     0.0      NaN      NaN\n",
      "          AAPI        0.0      NaN      NaN\n",
      "          AIAN        0.0      NaN      NaN\n",
      "          Black       0.0      NaN      NaN\n",
      "          Hispanic    0.0      NaN      NaN\n",
      "          Unknown     0.0      NaN      NaN\n",
      "          White       0.0      NaN      NaN\n",
      "Bhavani   >1 Race    89.8     85.2     94.3\n",
      "          AAPI       -1.3     -4.3      1.7\n",
      "          AIAN     -336.2   -349.2   -323.2\n",
      "          Black      53.3     52.5     54.2\n",
      "          Hispanic   69.7     67.9     71.4\n",
      "          Unknown    -2.2     -3.9     -0.6\n",
      "          White       9.2      8.9      9.5\n",
      "Colorado  >1 Race    28.2     22.8     33.5\n",
      "          AAPI        3.1     -0.2      6.4\n",
      "          AIAN     -359.0   -370.9   -347.1\n",
      "          Black      41.3     40.4     42.2\n",
      "          Hispanic   48.3     46.5     50.1\n",
      "          Unknown    -8.3     -9.9     -6.7\n",
      "          White       9.2      8.9      9.5\n",
      "Lottery   >1 Race     1.5     -5.0      8.1\n",
      "          AAPI       -2.3     -6.2      1.7\n",
      "          AIAN        2.8    -15.5     21.1\n",
      "          Black       0.9     -0.1      2.0\n",
      "          Hispanic    3.2      0.9      5.4\n",
      "          Unknown     1.5     -0.6      3.5\n",
      "          White      -0.3     -0.7      0.0\n",
      "NY SOFA   >1 Race    -8.1    -14.4     -1.8\n",
      "          AAPI       -6.5    -10.1     -2.8\n",
      "          AIAN     -100.0   -116.0    -84.0\n",
      "          Black      16.5     15.4     17.5\n",
      "          Hispanic    9.9      7.8     12.1\n",
      "          Unknown     7.9      6.0      9.7\n",
      "          White      13.6     13.3     13.9\n",
      "Pure SOFA >1 Race    33.4     28.2     38.7\n",
      "          AAPI        4.4      1.2      7.6\n",
      "          AIAN     -367.3   -379.3   -355.4\n",
      "          Black      40.8     40.0     41.7\n",
      "          Hispanic   46.3     44.5     48.1\n",
      "          Unknown   -16.2    -17.8    -14.5\n",
      "          White      12.5     12.2     12.7\n",
      "------------------------------\n",
      "------------------------------ All Protocols - YLS Rate\n",
      "                       mean  ci95_lo  ci95_hi\n",
      "Protocol  Race                               \n",
      "Age       >1 Race   10735.0  10579.0  10891.0\n",
      "          AAPI       5315.0   5225.0   5405.0\n",
      "          AIAN      14314.0  13765.0  14863.0\n",
      "          Black      5517.0   5494.0   5540.0\n",
      "          Hispanic   8531.0   8478.0   8584.0\n",
      "          Unknown    4107.0   4060.0   4153.0\n",
      "          White      2553.0   2545.0   2561.0\n",
      "Baseline  >1 Race       0.0      NaN      NaN\n",
      "          AAPI          0.0      NaN      NaN\n",
      "          AIAN          0.0      NaN      NaN\n",
      "          Black         0.0      NaN      NaN\n",
      "          Hispanic      0.0      NaN      NaN\n",
      "          Unknown       0.0      NaN      NaN\n",
      "          White         0.0      NaN      NaN\n",
      "Bhavani   >1 Race    6890.0   6716.0   7065.0\n",
      "          AAPI       1162.0   1042.0   1282.0\n",
      "          AIAN     -14080.0 -14632.0 -13528.0\n",
      "          Black      2916.0   2890.0   2942.0\n",
      "          Hispanic   3748.0   3688.0   3808.0\n",
      "          Unknown     805.0    752.0    858.0\n",
      "          White      1048.0   1040.0   1057.0\n",
      "Colorado  >1 Race    4159.0   3933.0   4385.0\n",
      "          AAPI       1323.0   1195.0   1452.0\n",
      "          AIAN     -15120.0 -15622.0 -14619.0\n",
      "          Black      2226.0   2198.0   2253.0\n",
      "          Hispanic   2596.0   2529.0   2662.0\n",
      "          Unknown     105.0     50.0    160.0\n",
      "          White       698.0    689.0    708.0\n",
      "Lottery   >1 Race     106.0   -181.0    392.0\n",
      "          AAPI        -86.0   -233.0     60.0\n",
      "          AIAN        127.0   -645.0    898.0\n",
      "          Black        19.0    -17.0     55.0\n",
      "          Hispanic    136.0     48.0    225.0\n",
      "          Unknown      56.0    -11.0    123.0\n",
      "          White       -10.0    -21.0      2.0\n",
      "NY SOFA   >1 Race    1155.0    857.0   1454.0\n",
      "          AAPI        322.0    181.0    464.0\n",
      "          AIAN      -4417.0  -5088.0  -3746.0\n",
      "          Black       626.0    591.0    661.0\n",
      "          Hispanic    450.0    366.0    534.0\n",
      "          Unknown     326.0    262.0    389.0\n",
      "          White       377.0    366.0    388.0\n",
      "Pure SOFA >1 Race    3932.0   3702.0   4161.0\n",
      "          AAPI        993.0    860.0   1125.0\n",
      "          AIAN     -15514.0 -16016.0 -15012.0\n",
      "          Black      1957.0   1928.0   1985.0\n",
      "          Hispanic   2245.0   2172.0   2317.0\n",
      "          Unknown    -213.0   -267.0   -158.0\n",
      "          White       584.0    574.0    592.0\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*30, 'All Protocols - LS Rate')\n",
    "stats_race_n_50 = (stats_race_50\n",
    "    .groupby(['Protocol', 'Race'])['LS_rate'].agg(['mean', 'std', 'sem'])\n",
    "    .assign(ci95_lo = lambda df_:\n",
    "            df_['mean'] - 1.96* df_['sem'],\n",
    "            ci95_hi = lambda df_:\n",
    "            df_['mean'] + 1.96* df_['sem'],\n",
    "    )\n",
    "    .drop(['std','sem'], axis=1)\n",
    "    .round(4)\n",
    "    .mul(1000) # remove to do per patient, rather than per 1000 patients   \n",
    ")\n",
    "print(stats_race_n_50)\n",
    "print('-'*30)\n",
    "\n",
    "print('-'*30, 'All Protocols - YLS Rate')\n",
    "stats_Cho_race_n_50 = (stats_Cho_race_50\n",
    "    .groupby(['Protocol', 'Race'])['YLS_Cho_rate'].agg(['mean', 'std', 'sem'])\n",
    "    .assign(ci95_lo = lambda df_:\n",
    "            df_['mean'] - 1.96* df_['sem'],\n",
    "            ci95_hi = lambda df_:\n",
    "            df_['mean'] + 1.96* df_['sem'],\n",
    "    )\n",
    "    .drop(['std','sem'], axis=1)\n",
    "    .round(4)\n",
    "    .mul(1000).round(0) # remove to do per patient, rather than per 1000 patients   \n",
    ")\n",
    "print(stats_Cho_race_n_50)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd296147",
   "metadata": {},
   "source": [
    "## Table 2 - Overall Survival Rate, Allocation by Race, and Age-Adjusted Survival by Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f8b9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative way of deriving CIs over the parameters derived in the runs - i.e. traditional CIs across the rates in each run.\n",
    "\n",
    "def get_CIs_rates(df_, groups):\n",
    "    return (df_\n",
    "            .groupby(groups, as_index=True)\n",
    "            .agg(\n",
    "                Run=pd.NamedAgg(column=\"Run\", aggfunc=\"count\"),\n",
    "                Pop_N=pd.NamedAgg(column=\"Pop_N\", aggfunc=\"mean\"),\n",
    "                Survived=pd.NamedAgg(column=\"Survived\", aggfunc=\"mean\"),\n",
    "                Allocated=pd.NamedAgg(column=\"Allocated\", aggfunc=\"mean\"),\n",
    "                A_rate=pd.NamedAgg(column=\"A_rate\", aggfunc=\"mean\"),\n",
    "                A_std=pd.NamedAgg(column=\"A_rate\", aggfunc=\"std\"),\n",
    "                A_sem=pd.NamedAgg(column=\"A_rate\", aggfunc=\"sem\"),\n",
    "                S_rate=pd.NamedAgg(column=\"S_rate\", aggfunc=\"mean\"),\n",
    "                S_std=pd.NamedAgg(column=\"S_rate\", aggfunc=\"std\"),\n",
    "                S_sem=pd.NamedAgg(column=\"S_rate\", aggfunc=\"sem\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "            .assign(A_rate_CI_lo = lambda df_: df_['A_rate'] - 1.96* df_['A_sem'],\n",
    "                A_rate_CI_hi = lambda df_:df_['A_rate'] + 1.96* df_['A_sem'],\n",
    "                S_rate_CI_lo = lambda df_: df_['S_rate'] - 1.96* df_['S_sem'],\n",
    "                S_rate_CI_hi = lambda df_:df_['S_rate'] + 1.96* df_['S_sem'],\n",
    "            )\n",
    "            .round(4) #round all number to two decimal places\n",
    "            .set_index(groups)\n",
    "            .reindex(columns=['Run','Pop_N','Survived','Allocated','A_rate','A_rate_CI_lo','A_rate_CI_hi', 'S_rate', 'S_rate_CI_lo', 'S_rate_CI_hi'])\n",
    "            .reset_index()\n",
    "    )\n",
    "\n",
    "#            .drop(df.loc[df_['Protocol']=='Baseline'].index, inplace=True)\n",
    "\n",
    "def get_CIs_rates_with_AA(df_, groups):\n",
    "    return (df_\n",
    "            .groupby(groups, as_index=True)\n",
    "            .agg(\n",
    "                Run=pd.NamedAgg(column=\"Run\", aggfunc=\"count\"),\n",
    "                Pop_N=pd.NamedAgg(column=\"Pop_N\", aggfunc=\"mean\"),\n",
    "                Survived=pd.NamedAgg(column=\"Survived\", aggfunc=\"mean\"),\n",
    "                Allocated=pd.NamedAgg(column=\"Allocated\", aggfunc=\"mean\"),\n",
    "                A_rate=pd.NamedAgg(column=\"A_rate\", aggfunc=\"mean\"),\n",
    "                A_std=pd.NamedAgg(column=\"A_rate\", aggfunc=\"std\"),\n",
    "                A_sem=pd.NamedAgg(column=\"A_rate\", aggfunc=\"sem\"),\n",
    "                S_rate=pd.NamedAgg(column=\"S_rate\", aggfunc=\"mean\"),\n",
    "                S_std=pd.NamedAgg(column=\"S_rate\", aggfunc=\"std\"),\n",
    "                S_sem=pd.NamedAgg(column=\"S_rate\", aggfunc=\"sem\"),\n",
    "                Age_Adj_S_rate=pd.NamedAgg(column=\"Age_Adj_S_rate\", aggfunc=\"mean\"),\n",
    "                Age_Adj_S_std=pd.NamedAgg(column=\"Age_Adj_S_rate\", aggfunc=\"std\"),\n",
    "                Age_Adj_S_sem=pd.NamedAgg(column=\"Age_Adj_S_rate\", aggfunc=\"sem\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "            .assign(A_rate_CI_lo = lambda df_: df_['A_rate'] - 1.96* df_['A_sem'],\n",
    "                A_rate_CI_hi = lambda df_:df_['A_rate'] + 1.96* df_['A_sem'],\n",
    "                S_rate_CI_lo = lambda df_: df_['S_rate'] - 1.96* df_['S_sem'],\n",
    "                S_rate_CI_hi = lambda df_:df_['S_rate'] + 1.96* df_['S_sem'],\n",
    "                Age_Adj_S_rate_CI_lo = lambda df_: df_['Age_Adj_S_rate'] - 1.96* df_['Age_Adj_S_sem'],\n",
    "                Age_Adj_S_rate_CI_hi = lambda df_:df_['Age_Adj_S_rate'] + 1.96* df_['Age_Adj_S_sem'],\n",
    "            )\n",
    "            .round(4) #round all number to two decimal places\n",
    "            .set_index(groups)\n",
    "            .reindex(columns=['Run','Pop_N','Survived','Allocated','A_rate','A_rate_CI_lo','A_rate_CI_hi', 'S_rate', 'S_rate_CI_lo',\n",
    "                               'S_rate_CI_hi', 'Age_Adj_S_rate','Age_Adj_S_rate_CI_lo','Age_Adj_S_rate_CI_hi'])\n",
    "            .reset_index()\n",
    "    )\n",
    "\n",
    "def get_CIs_Cho(df_, groups):\n",
    "    return (df_\n",
    "            .groupby(groups, as_index=True)\n",
    "            .agg(\n",
    "                Run=pd.NamedAgg(column=\"Run\", aggfunc=\"count\"),\n",
    "                Pop_N=pd.NamedAgg(column=\"Pop_N\", aggfunc=\"mean\"),\n",
    "                LE_Total_Cho=pd.NamedAgg(column=\"LE_Total_Cho\", aggfunc=\"mean\"),\n",
    "                YLL_Cho=pd.NamedAgg(column=\"YLL_Cho\", aggfunc=\"mean\"),\n",
    "                YLL_Cho_std=pd.NamedAgg(column=\"YLL_Cho\", aggfunc=\"std\"),\n",
    "                YLL_Cho_sem=pd.NamedAgg(column=\"YLL_Cho\", aggfunc=\"sem\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "            .assign(YLL_Cho_CI_lo = lambda df_: df_['YLL_Cho'] - 1.96* df_['YLL_Cho_sem'],\n",
    "                YLL_Cho_CI_hi = lambda df_:df_['YLL_Cho'] + 1.96* df_['YLL_Cho_sem']\n",
    "            )\n",
    "            .round(4) #round all number to two decimal places\n",
    "            .set_index(groups)\n",
    "            .reindex(columns=['Run','Pop_N', 'LE_Total_Cho', 'YLL_Cho','YLL_Cho_CI_lo','YLL_Cho_CI_hi'])\n",
    "            .reset_index()\n",
    "    )\n",
    "\n",
    "##Currently have remove Age-Adjustment since it is hard to interpret in this context.\n",
    "def get_CIs_Cho_with_AA(df_, groups):\n",
    "    return (df_\n",
    "            .groupby(groups, as_index=True)\n",
    "            .agg(\n",
    "                Run=pd.NamedAgg(column=\"Run\", aggfunc=\"count\"),\n",
    "                Pop_N=pd.NamedAgg(column=\"Pop_N\", aggfunc=\"mean\"),\n",
    "                LE_Total_Cho=pd.NamedAgg(column=\"LE_Total_Cho\", aggfunc=\"mean\"),\n",
    "                YLL_Cho=pd.NamedAgg(column=\"YLL_Cho\", aggfunc=\"mean\"),\n",
    "                YLL_Cho_std=pd.NamedAgg(column=\"YLL_Cho\", aggfunc=\"std\"),\n",
    "                YLL_Cho_sem=pd.NamedAgg(column=\"YLL_Cho\", aggfunc=\"sem\"),\n",
    "                #Age_Adj_YLL_Cho_rate=pd.NamedAgg(column=\"Age_Adj_YLL_Cho_rate\", aggfunc=\"mean\"),\n",
    "                #Age_Adj_YLL_Cho_rate_std=pd.NamedAgg(column=\"Age_Adj_YLL_Cho_rate\", aggfunc=\"std\"),\n",
    "                #Age_Adj_YLL_Cho_rate_sem=pd.NamedAgg(column=\"Age_Adj_YLL_Cho_rate\", aggfunc=\"sem\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "            .assign(YLL_Cho_CI_lo = lambda df_: df_['YLL_Cho'] - 1.96* df_['YLL_Cho_sem'],\n",
    "                YLL_Cho_CI_hi = lambda df_:df_['YLL_Cho'] + 1.96* df_['YLL_Cho_sem'],\n",
    "                #Age_Adj_YLL_Cho_rate_CI_lo = lambda df_: df_['Age_Adj_YLL_Cho_rate'] - 1.96* df_['Age_Adj_YLL_Cho_rate_sem'],\n",
    "                #Age_Adj_YLL_Cho_rate_CI_hi = lambda df_:df_['Age_Adj_YLL_Cho_rate'] + 1.96* df_['Age_Adj_YLL_Cho_rate_sem'],\n",
    "            )\n",
    "            .round(4) #round all number to two decimal places\n",
    "            .set_index(groups)\n",
    "            .reindex(columns=['Run','Pop_N', 'LE_Total_Cho', 'YLL_Cho', 'YLL_Cho_CI_lo', 'YLL_Cho_CI_hi', 'Age_Adj_YLL_Cho_rate','Age_Adj_YLL_Cho_rate_CI_lo','Age_Adj_YLL_Cho_rate_CI_hi'])\n",
    "            .reset_index()\n",
    "    )\n",
    "\n",
    "#stats_overall_50_mean = pd.concat([stats_overall_50[(stats_overall_50['Protocol']=='Baseline')], get_CIs_rates(stats_overall_50[stats_overall_50.Protocol != 'Baseline'], ['Protocol'])])\n",
    "#stats_race_50_mean = pd.concat([stats_race_50[(stats_race_50['Protocol']=='Baseline')], get_CIs_rates_with_AA(stats_race_50[stats_race_50.Protocol != 'Baseline'], ['Protocol', 'Race'])])\n",
    "\n",
    "with pd.ExcelWriter(\"MC-50-Table_2_Allocation_Survival.xlsx\") as writer:\n",
    "# use to_excel function and specify the sheet_name and index\n",
    "    # to store the dataframe in specified sheet\n",
    "    # \n",
    "    pd.concat([stats_overall_50[(stats_overall_50['Protocol']=='Baseline')], \n",
    "               get_CIs_rates(stats_overall_50[stats_overall_50.Protocol != 'Baseline'], ['Protocol'])]).to_excel(writer, sheet_name=\"Overall\", index=False)\n",
    "    pd.concat([stats_race_50[(stats_race_50['Protocol']=='Baseline')], \n",
    "               get_CIs_rates_with_AA(stats_race_50[stats_race_50.Protocol != 'Baseline'], ['Protocol', 'Race'])]).to_excel(writer, sheet_name=\"Race\", index=False)\n",
    "    pd.concat([stats_age_50[(stats_age_50['Protocol']=='Baseline')], \n",
    "               get_CIs_rates_with_AA(stats_age_50[stats_age_50.Protocol != 'Baseline'], ['Protocol', 'Age_Group'])]).to_excel(writer, sheet_name=\"Age_Group\", index=False)\n",
    "    pd.concat([stats_COVID_50[(stats_COVID_50['Protocol']=='Baseline')], \n",
    "               get_CIs_rates_with_AA(stats_COVID_50[stats_COVID_50.Protocol != 'Baseline'], ['Protocol', 'COVID_Status'])]).to_excel(writer, sheet_name=\"COVID_Status\", index=False)\n",
    "    \n",
    "    pd.concat([stats_Cho_overall_50[(stats_Cho_overall_50['Protocol']=='Baseline')], \n",
    "               get_CIs_Cho(stats_Cho_overall_50[stats_Cho_overall_50.Protocol != 'Baseline'], ['Protocol'])]).to_excel(writer, sheet_name=\"Cho_Overall\", index=False)\n",
    "    pd.concat([stats_Cho_race_50[(stats_Cho_race_50['Protocol']=='Baseline')], \n",
    "               get_CIs_Cho_with_AA(stats_Cho_race_50[stats_Cho_race_50.Protocol != 'Baseline'], ['Protocol', 'Race'])]).to_excel(writer, sheet_name=\"Cho_Race\", index=False)\n",
    "    pd.concat([stats_Cho_age_50[(stats_Cho_age_50['Protocol']=='Baseline')], \n",
    "               get_CIs_Cho_with_AA(stats_Cho_age_50[stats_Cho_age_50.Protocol != 'Baseline'], ['Protocol', 'Age_Group'])]).to_excel(writer, sheet_name=\"Cho_Age_Group\", index=False)\n",
    "    pd.concat([stats_Cho_COVID_50[(stats_Cho_COVID_50['Protocol']=='Baseline')], \n",
    "               get_CIs_Cho_with_AA(stats_Cho_COVID_50[stats_Cho_COVID_50.Protocol != 'Baseline'], ['Protocol', 'COVID_Status'])]).to_excel(writer, sheet_name=\"Cho_COVID_Status\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f084e3d",
   "metadata": {},
   "source": [
    "## Table 3 - Lives Saved and Years of Life Saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e47e7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative way of deriving CIs over the parameters derived in the runs - i.e. traditional CIs across the rates in each run.\n",
    "\n",
    "def get_LS(df_, groups):\n",
    "    return (df_\n",
    "#            .assign(Lives_Saved = lambda df_1: df_1['Survived']-df_1['Exp_Surv'])\n",
    "#            .assign(LS_rate = lambda df_2: df_2['Lives_Saved']/df_2['Pop_N'],)\n",
    "            .groupby(groups, as_index=True)\n",
    "            .agg(\n",
    "                Run=pd.NamedAgg(column=\"Run\", aggfunc=\"count\"),\n",
    "                Pop_N=pd.NamedAgg(column=\"Pop_N\", aggfunc=\"mean\"),\n",
    "                Allocated=pd.NamedAgg(column=\"Allocated\", aggfunc=\"mean\"),\n",
    "                Survived=pd.NamedAgg(column=\"Survived\", aggfunc=\"mean\"),\n",
    "                Exp_Surv=pd.NamedAgg(column=\"Exp_Surv\", aggfunc=\"mean\"),\n",
    "                Lives_Saved=pd.NamedAgg(column=\"Lives_Saved\", aggfunc=\"mean\"),\n",
    "                LS_std=pd.NamedAgg(column=\"Lives_Saved\", aggfunc=\"std\"),\n",
    "                LS_sem=pd.NamedAgg(column=\"Lives_Saved\", aggfunc=\"sem\"),\n",
    "                LS_rate=pd.NamedAgg(column=\"LS_rate\", aggfunc=\"mean\"),\n",
    "                LS_rate_std=pd.NamedAgg(column=\"LS_rate\", aggfunc=\"std\"),\n",
    "                LS_rate_sem=pd.NamedAgg(column=\"LS_rate\", aggfunc=\"sem\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "            .assign(\n",
    "                LS_CI_lo = lambda df_3: df_3['Lives_Saved'] - 1.96* df_3['LS_sem'],\n",
    "                LS_CI_hi = lambda df_3:df_3['Lives_Saved'] + 1.96* df_3['LS_sem'],\n",
    "                LS_rate_CI_lo = lambda df_3: df_3['LS_rate'] - 1.96* df_3['LS_rate_sem'],\n",
    "                LS_rate_CI_hi = lambda df_3:df_3['LS_rate'] + 1.96* df_3['LS_rate_sem'],\n",
    "            )\n",
    "            .round(4) #round all number to two decimal places\n",
    "            .set_index(groups)\n",
    "            .reindex(columns=['Run','Pop_N','Allocated','Survived', 'Exp_Surv', 'Lives_Saved', 'LS_CI_lo', 'LS_CI_hi', 'LS_rate', 'LS_rate_CI_lo', 'LS_rate_CI_hi'])\n",
    "            .reset_index()\n",
    "    )\n",
    "\n",
    "def get_YLS_Cho(df_, groups):\n",
    "    return (df_\n",
    "            #.assign(YLS_Cho = lambda df_1: (df_1['LE_Total_Cho']-df_1['Cho_YLL'])-df_1['Exp_LE_Cho'])\n",
    "            #.assign(YLS_Cho_rate = lambda df_2: df_2['YLS_Cho']/df_2['Pop_N'],)\n",
    "            .groupby(groups, as_index=True)\n",
    "            .agg(\n",
    "                Run=pd.NamedAgg(column=\"Run\", aggfunc=\"count\"),\n",
    "                Pop_N=pd.NamedAgg(column=\"Pop_N\", aggfunc=\"mean\"),\n",
    "                LE_Total_Cho=pd.NamedAgg(column=\"LE_Total_Cho\", aggfunc=\"mean\"),\n",
    "                Exp_LE_Cho=pd.NamedAgg(column=\"Exp_LE_Cho\", aggfunc=\"mean\"),\n",
    "                YLS_Cho=pd.NamedAgg(column=\"YLS_Cho\", aggfunc=\"mean\"),\n",
    "                YLS_Cho_std=pd.NamedAgg(column=\"YLS_Cho\", aggfunc=\"std\"),\n",
    "                YLS_Cho_sem=pd.NamedAgg(column=\"YLS_Cho\", aggfunc=\"sem\"),\n",
    "                YLS_Cho_rate=pd.NamedAgg(column=\"YLS_Cho_rate\", aggfunc=\"mean\"),\n",
    "                YLS_Cho_rate_std=pd.NamedAgg(column=\"YLS_Cho_rate\", aggfunc=\"std\"),\n",
    "                YLS_Cho_rate_sem=pd.NamedAgg(column=\"YLS_Cho_rate\", aggfunc=\"sem\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "            .assign(YLS_Cho_CI_lo = lambda df_3: df_3['YLS_Cho'] - 1.96* df_3['YLS_Cho_sem'],\n",
    "                YLS_Cho_CI_hi = lambda df_3:df_3['YLS_Cho'] + 1.96* df_3['YLS_Cho_sem'],\n",
    "                YLS_Cho_rate_CI_lo = lambda df_3: df_3['YLS_Cho_rate'] - 1.96* df_3['YLS_Cho_rate_sem'],\n",
    "                YLS_Cho_rate_CI_hi = lambda df_3:df_3['YLS_Cho_rate'] + 1.96* df_3['YLS_Cho_rate_sem']\n",
    "            )\n",
    "            .round(4) #round all number to two decimal places\n",
    "            .set_index(groups)\n",
    "            .reindex(columns=['Run','Pop_N', 'LE_Total_Cho', 'Exp_LE_Cho', 'YLS_Cho','YLS_Cho_CI_lo','YLS_Cho_CI_hi', 'YLS_Cho_rate','YLS_Cho_rate_CI_lo','YLS_Cho_rate_CI_hi'])\n",
    "            .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "'''\n",
    "def get_LS_with_AA(df_, groups):\n",
    "    return (df_\n",
    "            .groupby(groups, as_index=True)\n",
    "            .agg(\n",
    "                Run=pd.NamedAgg(column=\"Run\", aggfunc=\"count\"),\n",
    "                Pop_N=pd.NamedAgg(column=\"Pop_N\", aggfunc=\"mean\"),\n",
    "                Survived=pd.NamedAgg(column=\"Pop_N\", aggfunc=\"mean\"),\n",
    "                Allocated=pd.NamedAgg(column=\"Pop_N\", aggfunc=\"mean\"),\n",
    "                S_rate=pd.NamedAgg(column=\"S_rate\", aggfunc=\"mean\"),\n",
    "                S_std=pd.NamedAgg(column=\"S_rate\", aggfunc=\"std\"),\n",
    "                S_sem=pd.NamedAgg(column=\"S_rate\", aggfunc=\"sem\"),\n",
    "                Age_Adj_S_rate=pd.NamedAgg(column=\"Age_Adj_S_rate\", aggfunc=\"mean\"),\n",
    "                Age_Adj_S_std=pd.NamedAgg(column=\"Age_Adj_S_rate\", aggfunc=\"std\"),\n",
    "                Age_Adj_S_sem=pd.NamedAgg(column=\"Age_Adj_S_rate\", aggfunc=\"sem\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "            .assign(S_rate_CI_lo = lambda df_: df_['S_rate'] - 1.96* df_['S_sem'],\n",
    "                S_rate_CI_hi = lambda df_:df_['S_rate'] + 1.96* df_['S_sem'],\n",
    "                Age_Adj_S_rate_CI_lo = lambda df_: df_['Age_Adj_S_rate'] - 1.96* df_['Age_Adj_S_sem'],\n",
    "                Age_Adj_S_rate_CI_hi = lambda df_:df_['Age_Adj_S_rate'] + 1.96* df_['Age_Adj_S_sem'],\n",
    "            )\n",
    "            .round(4) #round all number to two decimal places\n",
    "            .set_index(groups)\n",
    "            .reindex(columns=['Run','Pop_N','Survived','Allocated','A_rate','A_rate_CI_lo','A_rate_CI_hi', 'S_rate', 'S_rate_CI_lo',\n",
    "                               'S_rate_CI_hi', 'Age_Adj_S_rate','Age_Adj_S_rate_CI_lo','Age_Adj_S_rate_CI_hi'])\n",
    "            .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_YLS_Cho_with_AA(df_, groups):\n",
    "    return (df_\n",
    "            .groupby(groups, as_index=True)\n",
    "            .agg(\n",
    "                Run=pd.NamedAgg(column=\"Run\", aggfunc=\"count\"),\n",
    "                Pop_N=pd.NamedAgg(column=\"Pop_N\", aggfunc=\"mean\"),\n",
    "                LE_Total_Cho=pd.NamedAgg(column=\"LE_Total_Cho\", aggfunc=\"mean\"),\n",
    "                Cho_YLL=pd.NamedAgg(column=\"Cho_YLL\", aggfunc=\"mean\"),\n",
    "                Cho_YLL_std=pd.NamedAgg(column=\"Cho_YLL\", aggfunc=\"std\"),\n",
    "                Cho_YLL_sem=pd.NamedAgg(column=\"Cho_YLL\", aggfunc=\"sem\"),\n",
    "                Age_Adj_Cho_YLL=pd.NamedAgg(column=\"Age_Adj_Cho_YLL\", aggfunc=\"mean\"),\n",
    "                Age_Adj_Cho_YLL_std=pd.NamedAgg(column=\"Age_Adj_Cho_YLL\", aggfunc=\"std\"),\n",
    "                Age_Adj_Cho_YLL_sem=pd.NamedAgg(column=\"Age_Adj_Cho_YLL\", aggfunc=\"sem\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "            .assign(Cho_YLL_CI_lo = lambda df_: df_['Cho_YLL'] - 1.96* df_['Cho_YLL_sem'],\n",
    "                Cho_YLL_CI_hi = lambda df_:df_['Cho_YLL'] + 1.96* df_['Cho_YLL_sem'],\n",
    "                Age_Adj_Cho_YLL_CI_lo = lambda df_: df_['Age_Adj_Cho_YLL'] - 1.96* df_['Age_Adj_Cho_YLL_sem'],\n",
    "                Age_Adj_Cho_YLL_CI_hi = lambda df_:df_['Age_Adj_Cho_YLL'] + 1.96* df_['Age_Adj_Cho_YLL_sem'],\n",
    "            )\n",
    "            .round(4) #round all number to two decimal places\n",
    "            .set_index(groups)\n",
    "            .reindex(columns=['Run','Pop_N', 'LE_Total_Cho', 'Cho_YLL', 'Cho_YLL_CI_lo', 'Cho_YLL_CI_hi', 'Age_Adj_Cho_YLL','Age_Adj_Cho_YLL_CI_lo','Age_Adj_Cho_YLL_CI_hi'])\n",
    "            .reset_index()\n",
    "    )\n",
    "'''\n",
    "    \n",
    "\n",
    "#stats_overall_50_mean = pd.concat([stats_overall_50[(stats_overall_50['Protocol']=='Baseline')], get_LS(stats_overall_50[stats_overall_50.Protocol != 'Baseline'], ['Protocol'])])\n",
    "#stats_race_50_mean = pd.concat([stats_race_50[(stats_race_50['Protocol']=='Baseline')], get_LS_with_AA(stats_race_50[stats_race_50.Protocol != 'Baseline'], ['Protocol', 'Race'])])\n",
    "\n",
    "with pd.ExcelWriter(\"MC-50-Table_3_LS_and_YLS.xlsx\") as writer:\n",
    "# use to_excel function and specify the sheet_name and index\n",
    "    # to store the dataframe in specified sheet\n",
    "    get_LS(stats_overall_50[stats_overall_50.Protocol != 'Baseline'], ['Protocol']).to_excel(writer, sheet_name=\"Overall\", index=False)\n",
    "    get_LS(stats_race_50[stats_race_50.Protocol != 'Baseline'], ['Protocol', 'Race']).to_excel(writer, sheet_name=\"Race\", index=False)\n",
    "    get_LS(stats_age_50[stats_age_50.Protocol != 'Baseline'], ['Protocol', 'Age_Group']).to_excel(writer, sheet_name=\"Age_Group\", index=False)\n",
    "    get_LS(stats_COVID_50[stats_COVID_50.Protocol != 'Baseline'], ['Protocol', 'COVID_Status']).to_excel(writer, sheet_name=\"COVID_Status\", index=False)\n",
    "        \n",
    "    get_YLS_Cho(stats_Cho_overall_50[stats_Cho_overall_50.Protocol != 'Baseline'], ['Protocol']).to_excel(writer, sheet_name=\"Cho_Overall\", index=False)\n",
    "    get_YLS_Cho(stats_Cho_race_50[stats_Cho_race_50.Protocol != 'Baseline'], ['Protocol', 'Race']).to_excel(writer, sheet_name=\"Cho_Race\", index=False)\n",
    "    get_YLS_Cho(stats_Cho_age_50[stats_Cho_age_50.Protocol != 'Baseline'], ['Protocol', 'Age_Group']).to_excel(writer, sheet_name=\"Cho_Age_Group\", index=False)\n",
    "    get_YLS_Cho(stats_Cho_COVID_50[stats_Cho_COVID_50.Protocol != 'Baseline'], ['Protocol', 'COVID_Status']).to_excel(writer, sheet_name=\"Cho_COVID_Status\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec24b6e",
   "metadata": {},
   "source": [
    "T-Tests for significance of differences, White vs Hispanic, or White vs Black \\\n",
    "https://www.statology.org/pandas-t-test/ \\\n",
    "\n",
    "ttest_ind(white_group['survived'], other_group['survived']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c6b0ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Baseline - Black Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "Baseline - Hispanic Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhering2\\AppData\\Local\\Temp\\ipykernel_18684\\4107108120.py:7: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  print('Baseline - Black', ttest_ind(stats_race_50[(stats_race_50['Protocol']=='Baseline') & (stats_race_50['Race']=='White')]['S_rate'], stats_race_50[(stats_race_50['Protocol']=='Baseline') & (stats_race_50['Race']=='Black')]['S_rate'], equal_var=False))\n",
      "c:\\Users\\jhering2\\AppData\\Local\\miniconda3\\envs\\datasci\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:1214: RuntimeWarning: divide by zero encountered in divide\n",
      "  var *= np.divide(n, n-ddof)  # to avoid error on division by zero\n",
      "c:\\Users\\jhering2\\AppData\\Local\\miniconda3\\envs\\datasci\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:1214: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  var *= np.divide(n, n-ddof)  # to avoid error on division by zero\n",
      "C:\\Users\\jhering2\\AppData\\Local\\Temp\\ipykernel_18684\\4107108120.py:8: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  print('Baseline - Hispanic', ttest_ind(stats_race_50[(stats_race_50['Protocol']=='Baseline') & (stats_race_50['Race']=='White')]['S_rate'], stats_race_50[(stats_race_50['Protocol']=='Baseline') & (stats_race_50['Race']=='Hispanic')]['S_rate'], equal_var=False))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n#COVID T-Tests\\nbase_c0 = stats_overall_50[(stats_overall_50['Protocol']=='Baseline') & (stats_overall_50['COVID_Status']==0)]\\nbase_c1 = stats_overall_50[(stats_overall_50['Protocol']=='Baseline') & (stats_overall_50['COVID_Status']==1)]\\nNY_50_c0 = stats_overall_50[(stats_overall_50['Protocol']=='NY SOFA') & (stats_overall_50['COVID_Status']==0)]\\nNY_50_c1 = stats_overall_50[(stats_overall_50['Protocol']=='NY SOFA') & (stats_overall_50['COVID_Status']==1)]\\nAge_50_c0 = stats_overall_50[(stats_overall_50['Protocol']=='Age') & (stats_overall_50['COVID_Status']==0)]\\nAge_50_c1 = stats_overall_50[(stats_overall_50['Protocol']=='Age') & (stats_overall_50['COVID_Status']==1)]\\nLott_50_c0 = stats_overall_50[(stats_overall_50['Protocol']=='Lottery') & (stats_overall_50['COVID_Status']==0)]\\nLott_50_c1 = stats_overall_50[(stats_overall_50['Protocol']=='Lottery') & (stats_overall_50['COVID_Status']==1)]\\n\\nprint('Baseline - Neg', ttest_ind(base_avg['S_rate'], base_c0['S_rate'], equal_var=False))\\nprint('Baseline - Pos', ttest_ind(base_avg['S_rate'], base_c1['S_rate'], equal_var=False))\\nprint('NY SOFA - Neg', ttest_ind(NY_50_avg['S_rate'], NY_50_c0['S_rate'], equal_var=False))\\nprint('NY SOFA - Pos', ttest_ind(NY_50_avg['S_rate'], NY_50_c1['S_rate'], equal_var=False))\\nprint('Age - Neg', ttest_ind(Age_50_avg['S_rate'], Age_50_c0['S_rate'], equal_var=False))\\nprint('Age - Pos', ttest_ind(Age_50_avg['S_rate'], Age_50_c1['S_rate'], equal_var=False))\\nprint('Lottery - Neg', ttest_ind(Lott_50_avg['S_rate'], Lott_50_c0['S_rate'], equal_var=False))\\nprint('Lottery - Pos', ttest_ind(Lott_50_avg['S_rate'], Lott_50_c1['S_rate'], equal_var=False))\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "## OVERALL PERFORMANCE T_TEST - Lotter vs Other Protocol\n",
    "\n",
    "## RACIAL DISPARITIES T_TEST - White vs Other Race (within Protocol)\n",
    "print('-'*30)\n",
    "print('Baseline - Black', ttest_ind(stats_race_50[(stats_race_50['Protocol']=='Baseline') & (stats_race_50['Race']=='White')]['S_rate'], stats_race_50[(stats_race_50['Protocol']=='Baseline') & (stats_race_50['Race']=='Black')]['S_rate'], equal_var=False))\n",
    "print('Baseline - Hispanic', ttest_ind(stats_race_50[(stats_race_50['Protocol']=='Baseline') & (stats_race_50['Race']=='White')]['S_rate'], stats_race_50[(stats_race_50['Protocol']=='Baseline') & (stats_race_50['Race']=='Hispanic')]['S_rate'], equal_var=False))\n",
    "print('-'*30)\n",
    "\n",
    "## RACIAL PERFORMANCE T_TEST - Lottery vs Other Protocol (within Race)\n",
    "\n",
    "'''\n",
    "base_b = stats_race_50[(stats_race_50['Protocol']=='Baseline') & (stats_race_50['Race']=='Black')]\n",
    "base_h = stats_race_50[(stats_race_50['Protocol']=='Baseline') & (stats_race_50['Race']=='Hispanic')]\n",
    "base_w = stats_race_50[(stats_race_50['Protocol']=='Baseline') & (stats_race_50['Race']=='White')]\n",
    "base_avg = stats_overall_50[(stats_overall_50['Protocol']=='Baseline')]\n",
    "\n",
    "\n",
    "print('Baseline - Black', ttest_ind(base_w['S_rate'], base_b['S_rate'], equal_var=False))\n",
    "print('Baseline - Hispanic', ttest_ind(base_w['S_rate'], base_h['S_rate'], equal_var=False))\n",
    "print('-'*30)\n",
    "\n",
    "NY_50_b = stats_race_50[(stats_race_50['Protocol']=='NY SOFA') & (stats_race_50['Race']=='Black')]\n",
    "NY_50_h = stats_race_50[(stats_race_50['Protocol']=='NY SOFA') & (stats_race_50['Race']=='Hispanic')]\n",
    "NY_50_w = stats_race_50[(stats_race_50['Protocol']=='NY SOFA') & (stats_race_50['Race']=='White')]\n",
    "NY_50_avg = stats_overall_50[(stats_overall_50['Protocol']=='NY SOFA')]\n",
    "\n",
    "print('NY - Black', ttest_ind(NY_50_w['S_rate'], NY_50_b['S_rate'], equal_var=False))\n",
    "print('NY - Hispanic', ttest_ind(NY_50_w['S_rate'], NY_50_h['S_rate'], equal_var=False))\n",
    "print('-'*30)\n",
    "\n",
    "Age_50_b = stats_race_50[(stats_race_50['Protocol']=='Age') & (stats_race_50['Race']=='Black')]\n",
    "Age_50_h = stats_race_50[(stats_race_50['Protocol']=='Age') & (stats_race_50['Race']=='Hispanic')]\n",
    "Age_50_w = stats_race_50[(stats_race_50['Protocol']=='Age') & (stats_race_50['Race']=='White')]\n",
    "Age_50_avg = stats_overall_50[(stats_overall_50['Protocol']=='Age')]\n",
    "\n",
    "print('Age - Black', ttest_ind(Age_50_w['S_rate'], Age_50_b['S_rate'], equal_var=False))\n",
    "print('Age - Hispanic', ttest_ind(Age_50_w['S_rate'], Age_50_h['S_rate'], equal_var=False))\n",
    "print('-'*30)\n",
    "\n",
    "Lott_50_b = stats_race_50[(stats_race_50['Protocol']=='Lottery') & (stats_race_50['Race']=='Black')]\n",
    "Lott_50_h = stats_race_50[(stats_race_50['Protocol']=='Lottery') & (stats_race_50['Race']=='Hispanic')]\n",
    "Lott_50_w = stats_race_50[(stats_race_50['Protocol']=='Lottery') & (stats_race_50['Race']=='White')]\n",
    "Lott_50_avg = stats_overall_50[(stats_overall_50['Protocol']=='Lottery')]\n",
    "\n",
    "print('Lottery - Black', ttest_ind(Lott_50_w['S_rate'], Lott_50_b['S_rate'], equal_var=False))\n",
    "print('Lottery - Hispanic', ttest_ind(Lott_50_w['S_rate'], Lott_50_h['S_rate'], equal_var=False))\n",
    "print('-'*30)\n",
    "\n",
    "'''\n",
    "'''\n",
    "#COVID T-Tests\n",
    "base_c0 = stats_overall_50[(stats_overall_50['Protocol']=='Baseline') & (stats_overall_50['COVID_Status']==0)]\n",
    "base_c1 = stats_overall_50[(stats_overall_50['Protocol']=='Baseline') & (stats_overall_50['COVID_Status']==1)]\n",
    "NY_50_c0 = stats_overall_50[(stats_overall_50['Protocol']=='NY SOFA') & (stats_overall_50['COVID_Status']==0)]\n",
    "NY_50_c1 = stats_overall_50[(stats_overall_50['Protocol']=='NY SOFA') & (stats_overall_50['COVID_Status']==1)]\n",
    "Age_50_c0 = stats_overall_50[(stats_overall_50['Protocol']=='Age') & (stats_overall_50['COVID_Status']==0)]\n",
    "Age_50_c1 = stats_overall_50[(stats_overall_50['Protocol']=='Age') & (stats_overall_50['COVID_Status']==1)]\n",
    "Lott_50_c0 = stats_overall_50[(stats_overall_50['Protocol']=='Lottery') & (stats_overall_50['COVID_Status']==0)]\n",
    "Lott_50_c1 = stats_overall_50[(stats_overall_50['Protocol']=='Lottery') & (stats_overall_50['COVID_Status']==1)]\n",
    "\n",
    "print('Baseline - Neg', ttest_ind(base_avg['S_rate'], base_c0['S_rate'], equal_var=False))\n",
    "print('Baseline - Pos', ttest_ind(base_avg['S_rate'], base_c1['S_rate'], equal_var=False))\n",
    "print('NY SOFA - Neg', ttest_ind(NY_50_avg['S_rate'], NY_50_c0['S_rate'], equal_var=False))\n",
    "print('NY SOFA - Pos', ttest_ind(NY_50_avg['S_rate'], NY_50_c1['S_rate'], equal_var=False))\n",
    "print('Age - Neg', ttest_ind(Age_50_avg['S_rate'], Age_50_c0['S_rate'], equal_var=False))\n",
    "print('Age - Pos', ttest_ind(Age_50_avg['S_rate'], Age_50_c1['S_rate'], equal_var=False))\n",
    "print('Lottery - Neg', ttest_ind(Lott_50_avg['S_rate'], Lott_50_c0['S_rate'], equal_var=False))\n",
    "print('Lottery - Pos', ttest_ind(Lott_50_avg['S_rate'], Lott_50_c1['S_rate'], equal_var=False))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e90e3",
   "metadata": {},
   "source": [
    "# OFFCUTS and OLD CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab05773e",
   "metadata": {},
   "source": [
    "#### Raw Years of Life Lost Calculators\n",
    "Calculates years of life lost by taking the sum of the (i) LE and (ii) co-morbidity adjusted LE, for all those who are deceased (i.e. survived=0)\n",
    "*TO DO* = (1) Aggregate LE only on Survived=0, but Pop_N should count all within Age-Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d74af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### \n",
    "# WARNING THIS CALCULATOR HAS NOT BEEN HARMONIZED TO THE STANDARD CALC/ STRCUTURE USED FOR Lives Saved and Years of Life Saved (CHO)\n",
    "####\n",
    "\n",
    "\n",
    "from scipy.stats.distributions import chi2\n",
    "\n",
    "#DEFINE Raw LE Calculator#\n",
    "def get_raw_YLL(df_, groups, alpha=0.05):\n",
    "    return (df_\n",
    "        .fillna(0)\n",
    "        .assign(YLL = lambda df_1: df_1['LE'].where(df_1['Survived'] == 0, 0), ## if deceased, then retain life expectancy, otherwise 0 out (so that we sum to get YLLs).\n",
    "            Exp_LE = lambda df_: df_['Baseline_Surv']*df_['LE']*df_['Capacity']# Capacity x LE if patient would have survived with ventilator, otherwise 0 (if deceased even with ventilator)\n",
    "            ) \n",
    "        .groupby(groups, as_index=False)\n",
    "        .agg(Pop_N=pd.NamedAgg(column=\"LE\", aggfunc=\"count\"),\n",
    "             LE_Total=pd.NamedAgg(column=\"LE\", aggfunc=\"sum\"),\n",
    "             Exp_LE=pd.NamedAgg(column=\"Exp_LE\", aggfunc=\"sum\"),\n",
    "             YLL=pd.NamedAgg(column=\"YLL\", aggfunc=\"sum\"))\n",
    "        .assign(YLL_CI_lo = lambda df_2: (0.5*chi2.ppf(\n",
    "                    alpha/2, #alpha\n",
    "                    2*df_2['YLL'] #shape (N.B.: if shape is zero, then result should be defined as zero)\n",
    "                    )),\n",
    "                YLL_CI_hi = lambda df_2: (0.5*chi2.ppf(\n",
    "                    1 - alpha/2, #alpha\n",
    "                    2*(df_2['YLL']+1) #shape (N.B.: if shape is zero, then result should be defined as zero)\n",
    "                    ))\n",
    "            )\n",
    "        .round(2) #round all number to two decimal places\n",
    "        .set_index(groups)\n",
    "    )\n",
    "\n",
    "#DEFINE Age-Adjusted Raw LE Calculator#\n",
    "def get_age_adjusted_YLL(df_, groups, alpha=0.05):\n",
    "    \n",
    "    std_pop = pd.DataFrame({\n",
    "    'Age_Group': ['<25', '25-34', '35-44', '45-54', '55-64', '65-74', '75-84', '>85'],\n",
    "    'Std_Pop': [(0.013818 + 0.055317 + 0.145565 + 0.138646), 0.135573, 0.162613, 0.134834, 0.087247, 0.066037, 0.044842, 0.015508]})\n",
    "\n",
    "    if ('Age_Group' in groups): \n",
    "        groups_age = groups\n",
    "    else:\n",
    "        groups_age = groups + ['Age_Group']\n",
    "\n",
    "    return (df_\n",
    "        .fillna(0)\n",
    "        .assign(YLL = lambda df_0: df_0['LE'].where(df_0['Survived'] == 0, 0), ## if deceased, then retain life expectancy, otherwise 0 out (so that we sum to get YLLs).\n",
    "            Baseline_LE = lambda df_: df_['Baseline_Surv']*df_['LE'],# LE if patient would have survived with ventilator, otherwise 0 (if deceased even with ventilator)\n",
    "            Baseline_Cho_LE = lambda df_: df_['Baseline_Surv']*df_['Cho_LE'] # Cho_LE if patient would have survived with ventilator, otherwise 0 (if deceased even with ventilator)\n",
    "            )\n",
    "        .groupby(groups_age, as_index=True)\n",
    "        .agg(Pop_N=pd.NamedAgg(column=\"LE\", aggfunc=\"count\"),\n",
    "             LE_Total=pd.NamedAgg(column=\"LE\", aggfunc=\"sum\"),\n",
    "             YLL=pd.NamedAgg(column=\"YLL\", aggfunc=\"sum\"))\n",
    "        .reset_index()\n",
    "        .merge(std_pop, on='Age_Group') #bring in standard pop for age-adjustment\n",
    "        #Calculate Age-Adjusted YLL\n",
    "        .assign(Std_Pop = lambda df_0: df_0['Std_Pop'].mask(df_0['Pop_N'] == 0, 0), #zero out Std_Pop for each sub-group age-band where sub-group has no subjects (i.e. no AIAN in <25)\n",
    "            )\n",
    "        .assign(Age_Adj_YLL_var = lambda df_1: (df_1['Std_Pop']**2)*(df_1['YLL']/(df_1['Pop_N']**2)), #variance for each age_group to be summed for total variance of Race (see WA Health doc)\n",
    "                w_i = lambda df_1: df_1['Std_Pop']/df_1['Pop_N'], #calc w variabLE for each Age_Group and Race (use max for Race Fay and Freur, and avg for Race Tiwari mod)\n",
    "                Age_Adj_YLL = lambda df_3: (df_3['YLL']/df_3['Pop_N']) * df_3['Std_Pop'] * 100 #calculate the age-adjusted number of life years (https://seer.cancer.gov/seerstat/WebHelp/Rate_Algorithms.htm)\n",
    "            )\n",
    "        .assign(w_max = lambda df_2: df_2.groupby(groups)['w_i'].transform('max')) #find max pop weight for Fay and Freur CIs (note use of transform, see here https://stackoverflow.com/questions/35640364/python-pandas-max-value-in-a-group-as-a-new-column\n",
    "        .groupby(groups, as_index=False).sum(numeric_only=True)\n",
    "        .assign(w_max = lambda df_3: df_3['w_max']/len(df_.groupby('Age_Group').count())) #was 8 #divide sum of max pop weights by number of age-groups (to re-idnetify the max pop weight for Race)\n",
    "        .assign(Age_Adj_YLL_CI_lo = lambda df_3: \n",
    "                    (df_3['Age_Adj_YLL_var'])/(2*df_3['Age_Adj_YLL']) *\n",
    "                    chi2.ppf(alpha/2, #alpha \n",
    "                        (2*df_3['Age_Adj_YLL']**2)/df_3['Age_Adj_YLL_var']), #shape\n",
    "                Age_Adj_YLL_CI_hi = lambda df_3: \n",
    "                    ((df_3['Age_Adj_YLL_var']+df_3['w_max']**2)/(2*(df_3['Age_Adj_YLL']+df_3['w_max']))) *\n",
    "                    chi2.ppf(1-alpha/2, # alpha\n",
    "                        (2*(df_3['Age_Adj_YLL']+df_3['w_max'])**2)/(df_3['Age_Adj_YLL_var']+df_3['w_max']**2)) #shape\n",
    "            )\n",
    "        .drop(['LE_Total', 'Pop_N', 'YLL', 'Age_Adj_YLL_var', 'Std_Pop', 'w_i', 'w_max'], axis=1)\n",
    "        .round(2) #round all numbers to 2 decimals places\n",
    "        .set_index(groups)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328faeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "#NOTE: the following code generates CIs that are *means* of the Fay-Feur individual CIs for each RUN\n",
    "#####\n",
    "\n",
    "#Overall Stats\n",
    "print(stats_overall_50.groupby(['Protocol']).mean())\n",
    "print(stats_race_50.groupby(['Protocol', 'Race']).mean())\n",
    "\n",
    "with pd.ExcelWriter(\"MC-50-Table_2_old.xlsx\") as writer:\n",
    "# use to_excel function and specify the sheet_name and index\n",
    "    # to store the dataframe in specified sheet\n",
    "    stats_overall_50.groupby(['Protocol']).mean().to_excel(writer, sheet_name=\"Overall\")\n",
    "    stats_race_50.groupby(['Protocol', 'Race']).mean().to_excel(writer, sheet_name=\"Race\")\n",
    "    stats_age_50.groupby(['Protocol', 'Age_Group']).mean().to_excel(writer, sheet_name=\"Age Group\")\n",
    "    stats_COVID_50.groupby(['Protocol', 'COVID_Status']).mean().to_excel(writer, sheet_name=\"COVID Status\")\n",
    "    stats_YLL_overall_50.groupby(['Protocol']).mean().to_excel(writer, sheet_name=\"YLL_Overall\")\n",
    "    stats_YLL_race_50.groupby(['Protocol', 'Race']).mean().to_excel(writer, sheet_name=\"YLL_Race\")\n",
    "    stats_YLL_age_50.groupby(['Protocol', 'Age_Group']).mean().to_excel(writer, sheet_name=\"YLL_Age_Group\")\n",
    "    stats_YLL_COVID_50.groupby(['Protocol', 'COVID_Status']).mean().to_excel(writer, sheet_name=\"YLL_COVID_Status\")\n",
    "    stats_Cho_overall_50.groupby(['Protocol']).mean().to_excel(writer, sheet_name=\"Cho_Overall\")\n",
    "    stats_Cho_race_50.groupby(['Protocol', 'Race']).mean().to_excel(writer, sheet_name=\"Cho_Race\")\n",
    "    stats_Cho_age_50.groupby(['Protocol', 'Age_Group']).mean().to_excel(writer, sheet_name=\"Cho_Age_Group\")\n",
    "    stats_Cho_COVID_50.groupby(['Protocol', 'COVID_Status']).mean().to_excel(writer, sheet_name=\"Cho_COVID_Status\")\n",
    "'''\n",
    "print('-'*30, 'All Protocols')\n",
    "stats_All = (stats_overall_50\n",
    "    .groupby(['Run','Protocol'])['Survived'].agg(['mean', 'std', 'sem'])\n",
    "    .assign(ci95_hi = lambda df_:\n",
    "            df_['mean'] + 1.96* df_['sem'],\n",
    "            ci95_lo = lambda df_:\n",
    "            df_['mean'] - 1.96* df_['sem']\n",
    "    )\n",
    ")\n",
    "print(stats_All)\n",
    "print('-'*30)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e710b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jhering2\\AppData\\Local\\Temp\\ipykernel_9976\\387304144.py:56: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  .groupby(groups, as_index=False).sum()\n",
      "C:\\Users\\jhering2\\AppData\\Local\\Temp\\ipykernel_9976\\2602674352.py:49: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  .groupby(groups, as_index=False).sum()\n",
      "C:\\Users\\jhering2\\AppData\\Local\\Temp\\ipykernel_9976\\387304144.py:56: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  .groupby(groups, as_index=False).sum()\n",
      "C:\\Users\\jhering2\\AppData\\Local\\Temp\\ipykernel_9976\\2602674352.py:49: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  .groupby(groups, as_index=False).sum()\n",
      "C:\\Users\\jhering2\\AppData\\Local\\Temp\\ipykernel_9976\\3781889545.py:5: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  pd.concat([get_raw_stats(df_50_NY, ['Run','Protocol']), get_age_adjusted_stats(df_50_NY, ['Run','Protocol'])],\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "concat() got multiple values for argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m##COMBINED\u001b[39;00m\n\u001b[0;32m      2\u001b[0m stats_overall_50 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([\n\u001b[0;32m      3\u001b[0m     pd\u001b[39m.\u001b[39mconcat([get_raw_stats(df_baseline, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), get_age_adjusted_stats(df_baseline, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[0;32m      4\u001b[0m                get_raw_LE(df_baseline, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), get_age_adjusted_LE(df_baseline, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m])], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreset_index(),\n\u001b[1;32m----> 5\u001b[0m     pd\u001b[39m.\u001b[39;49mconcat([get_raw_stats(df_50_NY, [\u001b[39m'\u001b[39;49m\u001b[39mRun\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mProtocol\u001b[39;49m\u001b[39m'\u001b[39;49m]), get_age_adjusted_stats(df_50_NY, [\u001b[39m'\u001b[39;49m\u001b[39mRun\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mProtocol\u001b[39;49m\u001b[39m'\u001b[39;49m])],\n\u001b[0;32m      6\u001b[0m               get_raw_LE(df_50_NY, [\u001b[39m'\u001b[39;49m\u001b[39mRun\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mProtocol\u001b[39;49m\u001b[39m'\u001b[39;49m]), get_age_adjusted_LE(df_50_NY, [\u001b[39m'\u001b[39;49m\u001b[39mRun\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mProtocol\u001b[39;49m\u001b[39m'\u001b[39;49m]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mreset_index(),\n\u001b[0;32m      7\u001b[0m     pd\u001b[39m.\u001b[39mconcat([get_raw_stats(df_50_Age, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), get_age_adjusted_stats(df_50_Age, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m])],\n\u001b[0;32m      8\u001b[0m               get_raw_LE(df_50_Age, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), get_age_adjusted_LE(df_50_Age, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreset_index(),\n\u001b[0;32m      9\u001b[0m     pd\u001b[39m.\u001b[39mconcat([get_raw_stats(df_50_Lott, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), get_age_adjusted_stats(df_50_Lott, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m])],\n\u001b[0;32m     10\u001b[0m               get_raw_LE(df_50_Lott, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), get_age_adjusted_LE(df_50_Lott, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreset_index(),\n\u001b[0;32m     11\u001b[0m     pd\u001b[39m.\u001b[39mconcat([get_raw_stats(df_50_Bhavani, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), get_age_adjusted_stats(df_50_Bhavani, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m])],\n\u001b[0;32m     12\u001b[0m               get_raw_LE(df_50_Bhavani, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), get_age_adjusted_LE(df_50_Bhavani, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreset_index(),\n\u001b[0;32m     13\u001b[0m     pd\u001b[39m.\u001b[39mconcat([get_raw_stats(df_50_Colorado, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), get_age_adjusted_stats(df_50_Colorado, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m])],\n\u001b[0;32m     14\u001b[0m               get_raw_LE(df_50_Colorado, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), get_age_adjusted_LE(df_50_Colorado, [\u001b[39m'\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mProtocol\u001b[39m\u001b[39m'\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreset_index()\n\u001b[0;32m     15\u001b[0m ])\n\u001b[0;32m     16\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mstats_race_50 = pd.concat([\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m    pd.concat([get_raw_stats(df_baseline, ['Run','Protocol', 'Race']), get_age_adjusted_stats(df_baseline, ['Run','Protocol', 'Race'])], axis=1).reset_index(),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39m])\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m###Use below to convert Stats to excel sheets####\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jhering2\\Miniconda3\\envs\\myenv\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: concat() got multiple values for argument 'axis'"
     ]
    }
   ],
   "source": [
    "##COMBINED\n",
    "stats_overall_50 = pd.concat([\n",
    "    pd.concat([get_raw_stats(df_baseline, ['Run','Protocol']), get_age_adjusted_stats(df_baseline, ['Run','Protocol']),\n",
    "               get_raw_LE(df_baseline, ['Run','Protocol']), get_age_adjusted_LE(df_baseline, ['Run','Protocol'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_NY, ['Run','Protocol']), get_age_adjusted_stats(df_50_NY, ['Run','Protocol'])],\n",
    "              get_raw_LE(df_50_NY, ['Run','Protocol']), get_age_adjusted_LE(df_50_NY, ['Run','Protocol']), axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Age, ['Run','Protocol']), get_age_adjusted_stats(df_50_Age, ['Run','Protocol'])],\n",
    "              get_raw_LE(df_50_Age, ['Run','Protocol']), get_age_adjusted_LE(df_50_Age, ['Run','Protocol']), axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Lott, ['Run','Protocol']), get_age_adjusted_stats(df_50_Lott, ['Run','Protocol'])],\n",
    "              get_raw_LE(df_50_Lott, ['Run','Protocol']), get_age_adjusted_LE(df_50_Lott, ['Run','Protocol']), axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Bhavani, ['Run','Protocol']), get_age_adjusted_stats(df_50_Bhavani, ['Run','Protocol'])],\n",
    "              get_raw_LE(df_50_Bhavani, ['Run','Protocol']), get_age_adjusted_LE(df_50_Bhavani, ['Run','Protocol']), axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Colorado, ['Run','Protocol']), get_age_adjusted_stats(df_50_Colorado, ['Run','Protocol'])],\n",
    "              get_raw_LE(df_50_Colorado, ['Run','Protocol']), get_age_adjusted_LE(df_50_Colorado, ['Run','Protocol']), axis=1).reset_index()\n",
    "])\n",
    "'''\n",
    "stats_race_50 = pd.concat([\n",
    "    pd.concat([get_raw_stats(df_baseline, ['Run','Protocol', 'Race']), get_age_adjusted_stats(df_baseline, ['Run','Protocol', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_NY, ['Run','Protocol', 'Race']), get_age_adjusted_stats(df_50_NY, ['Run','Protocol', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Age, ['Run','Protocol', 'Race']), get_age_adjusted_stats(df_50_Age, ['Run','Protocol', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Lott, ['Run','Protocol', 'Race']), get_age_adjusted_stats(df_50_Lott, ['Run','Protocol', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Bhavani, ['Run','Protocol', 'Race']), get_age_adjusted_stats(df_50_Bhavani, ['Run','Protocol', 'Race'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Colorado, ['Run','Protocol', 'Race']), get_age_adjusted_stats(df_50_Colorado, ['Run','Protocol', 'Race'])], axis=1).reset_index()\n",
    "])\n",
    "\n",
    "stats_age_50 = pd.concat([\n",
    "    pd.concat([get_raw_stats(df_baseline, ['Run','Protocol', 'Age_Group']), get_age_adjusted_stats(df_baseline, ['Run','Protocol', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_NY, ['Run','Protocol', 'Age_Group']), get_age_adjusted_stats(df_50_NY, ['Run','Protocol', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Age, ['Run','Protocol', 'Age_Group']), get_age_adjusted_stats(df_50_Age, ['Run','Protocol', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Lott, ['Run','Protocol', 'Age_Group']), get_age_adjusted_stats(df_50_Lott, ['Run','Protocol', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Bhavani, ['Run','Protocol', 'Age_Group']), get_age_adjusted_stats(df_50_Bhavani, ['Run','Protocol', 'Age_Group'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Colorado, ['Run','Protocol', 'Age_Group']), get_age_adjusted_stats(df_50_Colorado, ['Run','Protocol', 'Age_Group'])], axis=1).reset_index()\n",
    "])\n",
    "\n",
    "stats_COVID_50 = pd.concat([\n",
    "    pd.concat([get_raw_stats(df_baseline, ['Run','Protocol', 'COVID_Status']), get_age_adjusted_stats(df_baseline, ['Run','Protocol', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_NY, ['Run','Protocol', 'COVID_Status']), get_age_adjusted_stats(df_50_NY, ['Run','Protocol', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Age, ['Run','Protocol', 'COVID_Status']), get_age_adjusted_stats(df_50_Age, ['Run','Protocol', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Lott, ['Run','Protocol', 'COVID_Status']), get_age_adjusted_stats(df_50_Lott, ['Run','Protocol', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Bhavani, ['Run','Protocol', 'COVID_Status']), get_age_adjusted_stats(df_50_Bhavani, ['Run','Protocol', 'COVID_Status'])], axis=1).reset_index(),\n",
    "    pd.concat([get_raw_stats(df_50_Colorado, ['Run','Protocol', 'COVID_Status']), get_age_adjusted_stats(df_50_Colorado, ['Run','Protocol', 'COVID_Status'])], axis=1).reset_index()\n",
    "])\n",
    "'''\n",
    "\n",
    "###Use below to convert Stats to excel sheets####\n",
    "\n",
    "'''\n",
    "print('-'*30, 'All Protocols')\n",
    "stats_All = (stats_overall_50\n",
    "    .groupby(['Run','Protocol'])['Survived'].agg(['mean', 'std', 'sem'])\n",
    "    .assign(ci95_hi = lambda df_:\n",
    "            df_['mean'] + 1.96* df_['sem'],\n",
    "            ci95_lo = lambda df_:\n",
    "            df_['mean'] - 1.96* df_['sem']\n",
    "    )\n",
    ")\n",
    "print(stats_All)\n",
    "print('-'*30)\n",
    "'''\n",
    "with pd.ExcelWriter(\"MC-50-results-stats.xlsx\") as writer:\n",
    "# use to_excel function and specify the sheet_name and index\n",
    "    # to store the dataframe in specified sheet\n",
    "    stats_overall_50.to_excel(writer, sheet_name=\"Overall\")\n",
    "#    stats_race_50.to_excel(writer, sheet_name=\"Race\")\n",
    "#    stats_age_50.to_excel(writer, sheet_name=\"Age Group\")\n",
    "#    stats_COVID_50.to_excel(writer, sheet_name=\"COVID Status\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd5d0a8147fa3de6a86df2ea899fcd7eaa3fdbc819680b9fed256305e6d97914"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
