{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b0c451",
   "metadata": {},
   "source": [
    "# Preliminaries and Dataframe Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7937a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "#Import Encounters from Database Query\n",
    "df = pd.read_pickle(\"encounters.pkl\")\n",
    "\n",
    "#Formatting\n",
    "plt.rcParams['font.family'] = 'Times New Roman'  # Set plt shows font to Times New Roman\n",
    "plt.rcParams['axes.grid'] = True  # Ensure line graphs display on graphs\n",
    "sns.set_palette(sns.color_palette('Set2')) #set color palette to a nice seaborn style https://seaborn.pydata.org/tutorial/color_palettes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6ac3b",
   "metadata": {},
   "source": [
    "### Monte Carlo Model for 50% Capacity\n",
    "Extending the approach of Bhavani et al., our model simulates an n/20 (i.e. 5%, 10%...95% capacity, where n = <20>) ventilator shortage by: (1) randomly sampling 20 patients from our dataset, and assigning them to ten pairs (A and B), (2) if n>10, assigning ventilators to *both* patients in the first n/2 pairs (i.e. A=1, B=1), and if n≤10 assigning no ventilator to both patients in n/2 pairs (i.e. A=0, B=0), (3) ranking the individuals in each remaining pair for priority based on the relevant protocol (i.e. A>B), 4) assigning a ventilator to the highest priority patient in each pair (e.g. A=1, B=0), and 4) repeating this process until all patients in our dataset have been assigned to receive or not receive a ventilator.\n",
    "\n",
    "The input is a datafrae that includes EncounterID, Age (as a tiebreaker for Bhavani), Protocol Score (SOFA Score, NY SOFA Band, Colorado Score, Bhavani Score, Age_Group), and Actual_Survival outcome.\n",
    "\n",
    "The output is a dataframe that includes Capacity, Protocol, Run, EncounterID, Allocated, Survived.\n",
    "\n",
    "For these simulations, we complete 1000 runs per protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b9bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing Simulation ###\n",
    "\n",
    "df_small_TEST = (df\n",
    "      .rename(columns={'Survived':'Actual_Survival'})\n",
    "      .reindex(columns=['EncounterID', 'Age', 'Maryland_Score', 'Actual_Survival'])\n",
    ")\n",
    "#MC for different degrees of scarcity with NY Protocol\n",
    "beds = 1\n",
    "patients = 2 #patients fixed level across simulations\n",
    "decisions = 3700 #number of monte carlo samples (i.e. ) per MC simulation\n",
    "runs = 10 #number of MC simulations per capacity level\n",
    "\n",
    "results_TEST_50 = pd.DataFrame()\n",
    "\n",
    "for i in range(runs): #iterate over each run\n",
    "      sample = (df_small_TEST\n",
    "      .sample(n=decisions, replace=False) #randomly shuffle dataframe\n",
    "      .assign(Protocol = 'Maryland', Run = i+1, Capacity = (beds/patients), Allocated=0, Survived = 0)\n",
    "      .assign(Decision = lambda df_1:\n",
    "                  np.arange(len(df_1)) // patients + 1\n",
    "            )\n",
    "      .assign(Rank=lambda df_2: df_2\n",
    "                  .sort_values('Age')\n",
    "                  .groupby(['Decision'])['Maryland_Score'].rank(method=\"first\")\n",
    "            )\n",
    "      .assign(Allocated=lambda df_3: \n",
    "                  df_3['Allocated'].mask(df_3['Rank'] <= beds, 1),\n",
    "            Survived = lambda df_3: \n",
    "                  df_3['Survived'].mask(df_3['Rank'] <= beds, df_3['Actual_Survival'])\n",
    "            )\n",
    "      )\n",
    "      results_TEST_50 = pd.concat([results_TEST_50, sample])\n",
    "\n",
    "#results_TEST_50.to_csv('MC_TEST_50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f2556d",
   "metadata": {},
   "source": [
    "### PRODUCTION Monte Carlo Sim (50% Scarcity)\n",
    "Following Code Blocks generate 1000 runs of simulation for \n",
    "- (1) Pure SOFA, \n",
    "- (2) NY SOFA, \n",
    "- (3) Age-Groups, \n",
    "- (4) Lottery, \n",
    "- (5) Bhavani Multi-Principle,\n",
    "- (6) Colorado (modified)\n",
    "\n",
    "The NY SOFA protocol assigns priority tiers by SOFA score (SOFA ≤7 = Tier 1; SOFA 8-11 = Tier 2; SOFA ≥12 = Tier 3), with ties broken through a lottery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ec3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NY Protocol (50% Scarcity)\n",
    "df_small_ny = (df\n",
    "      .rename(columns={'Survived':'Actual_Survival'})\n",
    "      .reindex(columns=['EncounterID', 'NY_Score', 'Actual_Survival'])\n",
    ")\n",
    "#MC for different degrees of scarcity with NY Protocol\n",
    "beds = 1\n",
    "patients = 2 #patients fixed level across simulations\n",
    "decisions = 3700 #number of monte carlo samples (i.e. ) per MC simulation\n",
    "runs = 1000 #number of MC simulations per capacity level\n",
    "\n",
    "results_NY_50 = pd.DataFrame()\n",
    "\n",
    "for i in range(runs): #iterate over each run\n",
    "      sample = (df_small_ny\n",
    "      .sample(n=decisions, replace=False) #randomly shuffle dataframe\n",
    "      .assign(Protocol = 2, Run = i+1, Capacity = (beds/patients), Allocated=0, Survived = 0)\n",
    "      .assign(Decision = lambda df_1:\n",
    "                  np.arange(len(df_1)) // patients + 1\n",
    "            )\n",
    "      .assign(Rank=lambda df_2: \n",
    "                  df_2.groupby(['Decision'])['NY_Score'].rank(method=\"first\")\n",
    "            )\n",
    "      .assign(Allocated=lambda df_3: \n",
    "                  df_3['Allocated'].mask(df_3['Rank'] <= beds, 1),\n",
    "            Survived = lambda df_3: \n",
    "                  df_3['Survived'].mask(df_3['Rank'] <= beds, df_3['Actual_Survival'])\n",
    "            )\n",
    "      )\n",
    "      results_NY_50 = pd.concat([results_NY_50, sample])\n",
    "\n",
    "results_NY_50.to_csv('MC_NY_50.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c596f",
   "metadata": {},
   "source": [
    "**Monte Carlo (Age-Banding)**\n",
    "\n",
    "The age-banding protocol assigns priority by 10-year age bins, with ties broken by lottery. Age bands are '<25', '25-34', '35-44', '45-54', '55-64', '65-74', '75-84', '>85'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "701c5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age, 50% Scarcity\n",
    "df_small_age = (df\n",
    "      .rename(columns={'Survived':'Actual_Survival'})\n",
    "      .reindex(columns=['EncounterID', 'Age_Group', 'Actual_Survival'])\n",
    ")\n",
    "#MC for different degrees of scarcity with NY Protocol\n",
    "beds = 1\n",
    "patients = 2 #patients fixed level across simulations\n",
    "decisions = 3700 #number of monte carlo samples (i.e. ) per MC simulation\n",
    "runs = 1000 #number of MC simulations per capacity level\n",
    "\n",
    "results_Age_50 = pd.DataFrame()\n",
    "\n",
    "for i in range(runs): #iterate over each run\n",
    "      sample = (df_small_age\n",
    "      .sample(n=decisions, replace=False) #randomly shuffle dataframe\n",
    "      .assign(Protocol = 3,\n",
    "            Run = i+1, \n",
    "            Capacity = (beds/patients), \n",
    "            Allocated=0, \n",
    "            Survived = 0, \n",
    "            )\n",
    "      .assign(Decision = lambda df_1:\n",
    "                  np.arange(len(df_1)) // patients + 1, \n",
    "            Age_Group_N = lambda df_1:\n",
    "                  df_1['Age_Group'].map({'<25': 1, '25-34': 2, '35-44': 3, '45-54': 4, '55-64': 5, '65-74': 6, '75-84': 7, '>85': 8}).astype(int)\n",
    "            )\n",
    "      .assign(Rank=lambda df_2: \n",
    "                  df_2.groupby(['Decision'])['Age_Group_N'].rank(method=\"first\")\n",
    "            )\n",
    "      .assign(Allocated=lambda df_3: \n",
    "                  df_3['Allocated'].mask(df_3['Rank'] <= beds, 1),\n",
    "            Survived = lambda df_3: \n",
    "                  df_3['Survived'].mask(df_3['Rank'] <= beds, df_3['Actual_Survival'])\n",
    "            )\n",
    "      .drop(['Age_Group_N'], axis=1)\n",
    "      )\n",
    "      results_Age_50 = pd.concat([results_Age_50, sample])\n",
    "\n",
    "results_Age_50.to_csv('MC_Age_50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d373643",
   "metadata": {},
   "source": [
    "**Lottery Protocol**\n",
    "\n",
    "The lottery protocol assigns a random number between 0 and 5000 to every patient, and then assigns priority to the patient in each pair who possesses the higher number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a68a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lottery, 50% Scarcity\n",
    "df_small_lott = (df\n",
    "      .rename(columns={'Survived':'Actual_Survival'})\n",
    "      .reindex(columns=['EncounterID', 'Actual_Survival'])\n",
    ")\n",
    "#MC for different degrees of scarcity with NY Protocol\n",
    "beds = 1\n",
    "patients = 2 #patients fixed level across simulations\n",
    "decisions = 3700 #number of monte carlo samples (i.e. ) per MC simulation\n",
    "runs = 1000 #number of MC simulations per capacity level\n",
    "\n",
    "results_Lott_50 = pd.DataFrame()\n",
    "\n",
    "for i in range(runs): #iterate over each run\n",
    "      sample = (df_small_lott\n",
    "      .sample(n=decisions, replace=False) #randomly shuffle dataframe\n",
    "      .assign(Protocol = 1, Run = i+1, Capacity = (beds/patients), Allocated=0, Survived = 0)\n",
    "      .assign(Random = np.random.randint(0,5000,size=3700), #generate random integer\n",
    "            Decision = lambda df_1:\n",
    "                  np.arange(len(df_1)) // patients + 1\n",
    "            )\n",
    "      .assign(Rank=lambda df_2: \n",
    "                  df_2.groupby(['Decision'])['Random'].rank(method=\"first\")\n",
    "            )\n",
    "      .assign(Allocated=lambda df_3: \n",
    "                  df_3['Allocated'].mask(df_3['Rank'] <= beds, 1),\n",
    "            Survived = lambda df_3: \n",
    "                  df_3['Survived'].mask(df_3['Rank'] <= beds, df_3['Actual_Survival'])\n",
    "            )\n",
    "      )\n",
    "      results_Lott_50 = pd.concat([results_Lott_50, sample])\n",
    "\n",
    "results_Lott_50.to_csv('MC_Lott_50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a521c9",
   "metadata": {},
   "source": [
    "**Maryland, 2017**\n",
    "\n",
    "The Maryland, 2017 protocol assigns points by SOFA bands (<9 SOFA = 1 pt; 9-11 SOFA = 2 pts; 12-14 SOFA = 3 pts; >14 SOFA = 4pts) and adds +3 points to the SOFA score of any patient with a “severe” comorbidity (understood as a van Walraven acute Elixhauser score >=4, i.e. the upper tertile of Elixhauser scores with a “90% predicted 1 year mortality” in Snow et al.).(7,12) Ties between patients in the Maryland protocol where then broken by course-grained age-bands (0-49, 50-69, 70-84, ≥85) and then by lottery. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da3407aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maryland, 50% Scarcity\n",
    "df_small_Maryland = (df\n",
    "      .rename(columns={'Survived':'Actual_Survival'})\n",
    "      .reindex(columns=['EncounterID', 'Maryland_Score', 'Age', 'Actual_Survival'])\n",
    "      .assign(Maryland_Age = lambda df_1:\n",
    "                  pd.cut(df_1['Age'], [0, 50, 70, 85, np.inf], labels=[1, 2, 3, 4])#.astype(int)\n",
    "      )\n",
    ")\n",
    "#MC for different degrees of scarcity with NY Protocol\n",
    "beds = 1\n",
    "patients = 2 #patients fixed level across simulations\n",
    "decisions = 3700 #number of monte carlo samples (i.e. ) per MC simulation\n",
    "runs = 1000 #number of MC simulations per capacity level\n",
    "\n",
    "results_Maryland_50 = pd.DataFrame()\n",
    "\n",
    "for i in range(runs): #iterate over each run\n",
    "      sample = (df_small_Maryland\n",
    "      .sample(n=decisions, replace=False) #randomly shuffle dataframe\n",
    "      .assign(Protocol = 4, Run = i+1, Capacity = (beds/patients), Allocated=0, Survived = 0)\n",
    "      .assign(Decision = lambda df_1:\n",
    "                  np.arange(len(df_1)) // patients + 1\n",
    "            )\n",
    "      .assign(Rank=lambda df_2: df_2\n",
    "                  #.sort_values('Maryland_Age')\n",
    "                  .groupby(['Decision'])['Maryland_Score'].rank(method=\"first\")\n",
    "            )\n",
    "      .assign(Allocated=lambda df_3: \n",
    "                  df_3['Allocated'].mask(df_3['Rank'] <= beds, 1),\n",
    "            Survived = lambda df_3: \n",
    "                  df_3['Survived'].mask(df_3['Rank'] <= beds, df_3['Actual_Survival'])\n",
    "            )\n",
    "      )\n",
    "      results_Maryland_50 = pd.concat([results_Maryland_50, sample])\n",
    "\n",
    "results_Maryland_50.to_csv('MC_Maryland_50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f58621",
   "metadata": {},
   "source": [
    "**Colorado**\n",
    "\n",
    "The Colorado protocol assigns points by SOFA band (≤5 SOFA = 1pts; 6-9 SOFA = 2 pts; 10-12 SOFA = 3pts, >12 SOFA = 4 pts), and by a modified Charlson comorbidity index, with ties broken by lottery (see p100 and Appendix E, p120 of Colorado et.al.).(11) \n",
    "\n",
    "In the original Colorado protocol, they suggested a modified SOFA score that excluded Creatinine sub-components. Because we did not have access to SOFA sub-components, we used the full SOFA score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fc5211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colorado, 50% Scarcity\n",
    "df_small_colorado = (df\n",
    "      .rename(columns={'Survived':'Actual_Survival'})\n",
    "      .reindex(columns=['EncounterID', 'Colorado_Score', 'Actual_Survival'])\n",
    ")\n",
    "#MC for different degrees of scarcity with NY Protocol\n",
    "beds = 1\n",
    "patients = 2 #patients fixed level across simulations\n",
    "decisions = 3700 #number of monte carlo samples (i.e. ) per MC simulation\n",
    "runs = 1000 #number of MC simulations per capacity level\n",
    "\n",
    "results_Colorado_50 = pd.DataFrame()\n",
    "\n",
    "for i in range(runs): #iterate over each run\n",
    "      sample = (df_small_colorado\n",
    "      .sample(n=decisions, replace=False) #randomly shuffle dataframe\n",
    "      .assign(Protocol = 5, Run = i+1, Capacity = (beds/patients), Allocated=0, Survived = 0)\n",
    "      .assign(Decision = lambda df_1:\n",
    "                  np.arange(len(df_1)) // patients + 1\n",
    "            )\n",
    "      .assign(Rank=lambda df_2: \n",
    "                  df_2.groupby(['Decision'])['Colorado_Score'].rank(method=\"first\")\n",
    "            )\n",
    "      .assign(Allocated=lambda df_3: \n",
    "                  df_3['Allocated'].mask(df_3['Rank'] <= beds, 1),\n",
    "            Survived = lambda df_3: \n",
    "                  df_3['Survived'].mask(df_3['Rank'] <= beds, df_3['Actual_Survival'])\n",
    "            )\n",
    "      )\n",
    "      results_Colorado_50 = pd.concat([results_Colorado_50, sample])\n",
    "\n",
    "results_Colorado_50.to_csv('MC_Colorado_50.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac391c0c",
   "metadata": {},
   "source": [
    "**Pure SOFA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2015f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pure SOFA, 50% Scarcity\n",
    "df_small_sofa = (df\n",
    "      .rename(columns={'Survived':'Actual_Survival'})\n",
    "      .reindex(columns=['EncounterID', 'InitialSOFA', 'Actual_Survival'])\n",
    ")\n",
    "#MC for different degrees of scarcity with NY Protocol\n",
    "beds = 1\n",
    "patients = 2 #patients fixed level across simulations\n",
    "decisions = 3700 #number of monte carlo samples (i.e. ) per MC simulation\n",
    "runs = 1000 #number of MC simulations per capacity level\n",
    "\n",
    "results_sofa_50 = pd.DataFrame()\n",
    "\n",
    "for i in range(runs): #iterate over each run\n",
    "      sample = (df_small_sofa\n",
    "      .sample(n=decisions, replace=False) #randomly shuffle dataframe\n",
    "      .assign(Protocol = 6, Run = i+1, Capacity = (beds/patients), Allocated=0, Survived = 0)\n",
    "      .assign(Decision = lambda df_1:\n",
    "                  np.arange(len(df_1)) // patients + 1\n",
    "            )\n",
    "      .assign(Rank=lambda df_2: \n",
    "                  df_2.groupby(['Decision'])['InitialSOFA'].rank(method=\"first\")\n",
    "            )\n",
    "      .assign(Allocated=lambda df_3: \n",
    "                  df_3['Allocated'].mask(df_3['Rank'] <= beds, 1),\n",
    "            Survived = lambda df_3: \n",
    "                  df_3['Survived'].mask(df_3['Rank'] <= beds, df_3['Actual_Survival'])\n",
    "            )\n",
    "      )\n",
    "      results_sofa_50 = pd.concat([results_sofa_50, sample])\n",
    "\n",
    "results_sofa_50.to_csv('MC_sofa_50.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb3d46ba7deccea0813b045b5a26367b0a53cb47223c8915d4a138cf32d4ee93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
